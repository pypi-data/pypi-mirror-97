Metadata-Version: 2.1
Name: aif360
Version: 0.4.0
Summary: IBM AI Fairness 360
Home-page: https://github.com/Trusted-AI/AIF360
Author: aif360 developers
Author-email: aif360@us.ibm.com
License: Apache License 2.0
Platform: UNKNOWN
Requires-Python: >=3.6
Description-Content-Type: text/markdown
Requires-Dist: numpy (>=1.16)
Requires-Dist: scipy (<1.6.0,>=1.2.0)
Requires-Dist: pandas (>=0.24.0)
Requires-Dist: scikit-learn (>=0.22.1)
Requires-Dist: matplotlib
Requires-Dist: tempeh
Provides-Extra: art
Requires-Dist: adversarial-robustness-toolbox (>=1.0.0) ; extra == 'art'
Provides-Extra: adversarialdebiasing
Requires-Dist: tensorflow (>=1.13.1) ; extra == 'adversarialdebiasing'
Provides-Extra: disparateimpactremover
Requires-Dist: BlackBoxAuditing ; extra == 'disparateimpactremover'
Provides-Extra: lime
Requires-Dist: lime ; extra == 'lime'
Provides-Extra: optimpreproc
Requires-Dist: cvxpy (>=1.0) ; extra == 'optimpreproc'
Provides-Extra: reductions
Requires-Dist: fairlearn (==0.4.6) ; extra == 'reductions'
Provides-Extra: all
Requires-Dist: adversarial-robustness-toolbox (>=1.0.0) ; extra == 'all'
Requires-Dist: pytest (>=3.5) ; extra == 'all'
Requires-Dist: tqdm ; extra == 'all'
Requires-Dist: jupyter ; extra == 'all'
Requires-Dist: sphinx ; extra == 'all'
Requires-Dist: lime ; extra == 'all'
Requires-Dist: fairlearn (==0.4.6) ; extra == 'all'
Requires-Dist: BlackBoxAuditing ; extra == 'all'
Requires-Dist: cvxpy (>=1.0) ; extra == 'all'
Requires-Dist: tensorflow (>=1.13.1) ; extra == 'all'
Requires-Dist: sphinx-rtd-theme ; extra == 'all'
Provides-Extra: docs
Requires-Dist: sphinx ; extra == 'docs'
Requires-Dist: sphinx-rtd-theme ; extra == 'docs'
Provides-Extra: notebooks
Requires-Dist: jupyter ; extra == 'notebooks'
Requires-Dist: tqdm ; extra == 'notebooks'
Provides-Extra: tests
Requires-Dist: pytest (>=3.5) ; extra == 'tests'
Requires-Dist: cvxpy (>=1.0) ; extra == 'tests'
Requires-Dist: tensorflow (>=1.13.1) ; extra == 'tests'
Requires-Dist: BlackBoxAuditing ; extra == 'tests'
Requires-Dist: lime ; extra == 'tests'
Requires-Dist: adversarial-robustness-toolbox (>=1.0.0) ; extra == 'tests'
Requires-Dist: fairlearn (==0.4.6) ; extra == 'tests'
Requires-Dist: jupyter ; extra == 'tests'
Requires-Dist: tqdm ; extra == 'tests'

The AI Fairness 360 toolkit is an open-source library to help detect and mitigate bias in machine
learning models. The AI Fairness 360 Python package includes a comprehensive set of metrics for datasets and models to
test for biases, explanations for these metrics, and algorithms to mitigate bias in datasets and models.

We have developed the package with extensibility in mind. This library is still in development. We encourage the
contribution of your datasets, metrics, explainers, and debiasing algorithms.

