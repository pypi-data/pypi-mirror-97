{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 356,
     "status": "ok",
     "timestamp": 1615318958793,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "HvSJBvXhD1f4"
   },
   "outputs": [],
   "source": [
    "# default_exp merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNgfqEQsD1gE"
   },
   "source": [
    "# Merge Data\n",
    "\n",
    "> This notebook was made to demonstrate how to merge datasets by matching a single columns values from two datasets. We add columns of data from a foreign dataset into the ACS data we downloaded in our last tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79LYg3-SD1gE"
   },
   "source": [
    "This Coding Notebook is the __second__ in a series.\n",
    "\n",
    "An Interactive version can be found here <a href=\"https://colab.research.google.com/github/karpatic/dataplay/blob/master/notebooks/02_Merge_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>.\n",
    "\n",
    "\n",
    "This colab and more can be found on our [webpage](https://karpatic.github.io/dataplay/). \n",
    "\n",
    "- Content covered in previous tutorials will be used in later tutorials. \n",
    "\n",
    "- __New code and or  information *should* have explanations and or descriptions__ attached. \n",
    "\n",
    "- Concepts or code covered in previous tutorials will be used without being explaining in entirety.\n",
    "\n",
    "- The [Dataplay](https://karpatic.github.io/dataplay/) Handbook development techniques covered in the [Datalabs](https://karpatic.github.io/datalabs/) Guidebook\n",
    "\n",
    "- __If content can not be found in the current tutorial and is not covered in previous tutorials, please let me know.__\n",
    "\n",
    "- This notebook has been optimized for Google Colabs ran on a Chrome Browser. \n",
    "\n",
    "- Statements found in the index page on view expressed, responsibility, errors and ommissions, use at risk, and licensing  extend throughout the tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YbEIVv1hD1gE"
   },
   "source": [
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/karpatic/datalab/master?filepath=%2Fnotebooks%2Findex.ipynb)\r\n",
    "[![Binder](https://pete88b.github.io/fastpages/assets/badges/colab.svg)](https://colab.research.google.com/github/karpatic/datalab/blob/master/notebooks/index.ipynb)\r\n",
    "[![Binder](https://pete88b.github.io/fastpages/assets/badges/github.svg)](https://github.com/karpatic/datalab/tree/master/notebooks/index.ipynb)\r\n",
    "[![Open Source Love svg3](https://badges.frapsoft.com/os/v3/open-source.svg?v=103)](https://github.com/ellerbrock/open-source-badges/)\r\n",
    "\r\n",
    "[![NPM License](https://img.shields.io/npm/l/all-contributors.svg?style=flat)](https://github.com/karpatic/dataplay/blob/master/LICENSE)\r\n",
    "[![Active](http://img.shields.io/badge/Status-Active-green.svg)](https://karpatic.github.io) \r\n",
    "[![Python Versions](https://img.shields.io/pypi/pyversions/dataplay.svg)](https://pypi.python.org/pypi/dataplay/)\r\n",
    "[![GitHub last commit](https://img.shields.io/github/last-commit/karpatic/dataplay.svg?style=flat)]() \r\n",
    "[![No Maintenance Intended](http://unmaintained.tech/badge.svg)](http://unmaintained.tech/) \r\n",
    "\r\n",
    "[![GitHub stars](https://img.shields.io/github/stars/karpatic/dataplay.svg?style=social&label=Star)](https://github.com/karpatic/dataplay) \r\n",
    "[![GitHub watchers](https://img.shields.io/github/watchers/karpatic/dataplay.svg?style=social&label=Watch)](https://github.com/karpatic/dataplay) \r\n",
    "[![GitHub forks](https://img.shields.io/github/forks/karpatic/dataplay.svg?style=social&label=Fork)](https://github.com/karpatic/dataplay) \r\n",
    "[![GitHub followers](https://img.shields.io/github/followers/karpatic.svg?style=social&label=Follow)](https://github.com/karpatic/dataplay) \r\n",
    "\r\n",
    "[![Tweet](https://img.shields.io/twitter/url/https/github.com/karpatic/dataplay.svg?style=social)](https://twitter.com/intent/tweet?text=Check%20out%20this%20%E2%9C%A8%20colab%20by%20@bniajfi%20https://github.com/karpatic/dataplay%20%F0%9F%A4%97) \r\n",
    "[![Twitter Follow](https://img.shields.io/twitter/follow/bniajfi.svg?style=social)](https://twitter.com/bniajfi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwUwHew_D1gF"
   },
   "source": [
    "## About this Tutorial: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9c50gR8MD1gF"
   },
   "source": [
    "### Whats Inside?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k2AlFGbRD1gF"
   },
   "source": [
    "#### __The Tutorial__\n",
    "\n",
    "In this notebook, the basics of how to perform a merge are introduced.\n",
    "\n",
    "- We will merge two datasets\n",
    "- We will merge two datasets using a crosswalk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FS3G6_U3D1gF"
   },
   "source": [
    "#### __Objectives__\n",
    "\n",
    "By the end of this tutorial users should have an understanding of:\n",
    "- How dataset merges are performed\n",
    "- The types different union approaches a merge can take\n",
    "- The 'mergeData' function, and how to use it in the future"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kdJu8nqRD1gG"
   },
   "source": [
    "# Guided Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qymk6Fz4D1gG"
   },
   "source": [
    "## SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpcD9LyaD1gG"
   },
   "source": [
    "Install these libraries onto the virtual environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 11941,
     "status": "ok",
     "timestamp": 1615318970383,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "oh6PQOCPD1gG"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install geopandas\n",
    "!pip install dataplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 11939,
     "status": "ok",
     "timestamp": 1615318970385,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "broVz9CiD1gG"
   },
   "outputs": [],
   "source": [
    "# @title Run: Install Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 217
    },
    "executionInfo": {
     "elapsed": 12410,
     "status": "error",
     "timestamp": 1615318970879,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "WHNby2viD1gH",
    "outputId": "0faaf675-7772-477e-9db0-53f4a40f47bc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/dataplay/acsDownload.py:27: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option('display.max_colwidth', -1)\n",
      "/usr/local/lib/python3.7/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/usr/local/lib/python3.7/dist-packages/dataplay/geoms.py\"\u001b[0;36m, line \u001b[0;32m283\u001b[0m\n\u001b[0;31m    elif (not (url and porg) ) or (\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#export\n",
    "# @title Run: Import Modules\n",
    "\n",
    "# These imports will handle everything\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dataplay.acsDownload import retrieve_acs_data\n",
    "from dataplay.intaker import Intake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12355,
     "status": "aborted",
     "timestamp": 1615318970828,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "GhM56HxKD1gH"
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "pd.set_option('max_colwidth', 20)\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.set_option('display.precision', 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BKLHgcV6D1gH"
   },
   "source": [
    "## Retrieve Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fuOhq_cPD1gI"
   },
   "source": [
    "Our example will merge two simple datasets; pulling CSA names using tract ID's.\n",
    "\n",
    "The __First__ dataset will be obtained from the Census' ACS 5-year serveys. \n",
    "\n",
    "Functions used to obtain this data were obtained from Tutorial 0) ACS: Explore and Download. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rooxA90ND1gI"
   },
   "source": [
    "\r\n",
    "The __Second__ dataset is from a publicly accessible link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pw1ouTxzD1gI"
   },
   "source": [
    "### Get the Principal dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6zzYmMMD1gI"
   },
   "source": [
    "We will use the function we created in our last tutorial to download the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12357,
     "status": "aborted",
     "timestamp": 1615318970835,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "ryomckMlD1gI"
   },
   "outputs": [],
   "source": [
    "# Our download function will use Baltimore City's tract, county and state as internal paramters\n",
    "# Change these values in the cell below using different geographic reference codes will change those parameters\n",
    "tract = '*'\n",
    "county = '510'\n",
    "state = '24'\n",
    "\n",
    "# Specify the download parameters the function will receieve here\n",
    "tableId = 'B19001'\n",
    "year = '17'\n",
    "saveAcs = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12344,
     "status": "aborted",
     "timestamp": 1615318970838,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "UI3cEX3HD1gI"
   },
   "outputs": [],
   "source": [
    "df = retrieve_acs_data(state, county, tract, tableId, year, saveAcs)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXi6kJeqD1gJ"
   },
   "source": [
    "### Get the Secondary Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDxVvio8D1gJ"
   },
   "source": [
    "Spatial data can be attained by using the 2010 Census Tract Shapefile Picking [Tool](https://www.census.gov/cgi-bin/geo/shapefiles/index.php?year=2010&layergroup=Census+Tracts) or search their website for\n",
    "Tiger/[Line](https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.2010.html) Shapefiles\n",
    "> The core TIGER/Line Files and Shapefiles do not include demographic data, but they do contain geographic entity codes (GEOIDs) that can be linked to the Census Bureau’s demographic data, available on data.census.gov.-census.gov\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ahE4lBxID1gJ"
   },
   "source": [
    "For this example, we will simply pull a local dataset containing columns labeling tracts within Baltimore City and their corresponding CSA (Community Statistical Area). Typically, we use this dataset internally as a \"crosswalk\" where-upon a succesfull merge using the tract column, will be merged with a 3rd dataset along it's CSA column.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12332,
     "status": "aborted",
     "timestamp": 1615318970840,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "pd2YNFM2D1gJ"
   },
   "outputs": [],
   "source": [
    "!curl https://bniajfi.org/vs_resources/CSA-to-Tract-2010.csv\t> CSA-to-Tract-2010.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12324,
     "status": "aborted",
     "timestamp": 1615318970841,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "2HCG2cfvD1gJ"
   },
   "outputs": [],
   "source": [
    "print('Boundaries Example:CSA-to-Tract-2010.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12324,
     "status": "aborted",
     "timestamp": 1615318970854,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "Zm7lfTwjD1gK"
   },
   "outputs": [],
   "source": [
    "# Get the Second dataset. \n",
    "# Our Example dataset contains Polygon Geometry information. \n",
    "# We want to merge this over to our principle dataset. \n",
    "# we will grab it by matching on either CSA or Tract\n",
    "\n",
    "# The url listed below is public.\n",
    "\n",
    "print('Tract 2 CSA Crosswalk : CSA-to-Tract-2010.csv')\n",
    "\n",
    "inFile = input(\"\\n Please enter the location of your file : \\n\" )\n",
    "\n",
    "crosswalk = pd.read_csv( inFile ) \n",
    "crosswalk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12314,
     "status": "aborted",
     "timestamp": 1615318970855,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "CWNBFJqWD1gK"
   },
   "outputs": [],
   "source": [
    "crosswalk.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vSnFy4XzD1gK"
   },
   "source": [
    "## Perform Merge & Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gf3RAuMsD1gK"
   },
   "source": [
    "The following picture does nothing important but serves as a friendly reminder of the 4 basic join types.\n",
    "\n",
    "<image src=\"https://docs.trifacta.com/download/attachments/123830435/JoinVennDiagram.png\" height='200px'/>\n",
    "\n",
    "- Left - returns all left records, only includes the right record if it has a match\n",
    "- Right - Returns all right records, only includes the left record if it has a match \n",
    "- Full - Returns all records regardless of keys matching\n",
    "- Inner - Returns only records where a key match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FmwqCdRoD1gK"
   },
   "source": [
    "Get Columns from both datasets to match on\n",
    "\n",
    "You can get these values from the column values above.\n",
    "\n",
    "Our Examples will work with the prompted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12304,
     "status": "aborted",
     "timestamp": 1615318970856,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "3iqderItD1gL"
   },
   "outputs": [],
   "source": [
    "print( 'Princpal Columns ' + str(crosswalk.columns) + '')\n",
    "left_on = input(\"Left on principal column: ('tract') \\n\" )\n",
    "print(' \\n ');\n",
    "print( 'Crosswalk Columns ' + str(crosswalk.columns) + '')\n",
    "right_on = input(\"Right on crosswalk column: ('TRACTCE10') \\n\" ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSLTtNX8D1gL"
   },
   "source": [
    "Specify how the merge will be performed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feCHThQdD1gL"
   },
   "source": [
    "We will perform a left merge in this example.\n",
    "\n",
    "It will return our Principal dataset with columns from the second dataset appended to records where their specified columns match.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12295,
     "status": "aborted",
     "timestamp": 1615318970857,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "DrX9evdxD1gL"
   },
   "outputs": [],
   "source": [
    "how = input(\"How: (‘left’, ‘right’, ‘outer’, ‘inner’) \" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9idjz0VD1gL"
   },
   "source": [
    "Actually perfrom the merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12286,
     "status": "aborted",
     "timestamp": 1615318970859,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "UhEgZLurD1gL"
   },
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df, crosswalk, left_on=left_on, right_on=right_on, how=how)\n",
    "merged_df = merged_df.drop(left_on, axis=1)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8wSqFefD1gM"
   },
   "source": [
    "As you can see, our Census data will now have a CSA appended to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12275,
     "status": "aborted",
     "timestamp": 1615318970860,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "H_JJ1oURD1gM"
   },
   "outputs": [],
   "source": [
    "# Save Data to User Specified File\n",
    "outFile = input(\"Please enter the new Filename to save the data to ('acs_csa_merge_test': \" )\n",
    "merged_df.to_csv(outFile+'.csv', quoting=csv.QUOTE_ALL) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnK_u4cgD1gM"
   },
   "source": [
    "## Final Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12267,
     "status": "aborted",
     "timestamp": 1615318970862,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "MIT1zW8nD1gM"
   },
   "outputs": [],
   "source": [
    "flag = input(\"Enter a URL? If not ACS data will be used. (Y/N):  \" )\n",
    "if (flag == 'y' or flag == 'Y'):\n",
    "  df = pd.read_csv( input(\"Please enter the location of your Principal file: \" ) )\n",
    "else:\n",
    "  tract = input(\"Please enter tract id (*): \" )\n",
    "  county = input(\"Please enter county id (510): \" )\n",
    "  state = input(\"Please enter state id (24): \" )\n",
    "  tableId = input(\"Please enter acs table id (B19001): \" ) \n",
    "  year = input(\"Please enter acs year (18): \" )\n",
    "  saveAcs = input(\"Save ACS? (Y/N): \" )\n",
    "  df = retrieve_acs_data(state, county, tract, tableId, year, saveAcs)\n",
    "\n",
    "print( 'Principal Columns ' + str(df.columns))\n",
    "\n",
    "print('Crosswalk Example: CSA-to-Tract-2010.csv')\n",
    "\n",
    "crosswalk = pd.read_csv( input(\"Please enter the location of your crosswalk file: \" ) )\n",
    "print( 'Crosswalk Columns ' + str(crosswalk.columns) + '\\n')\n",
    "\n",
    "left_on = input(\"Left on: \" )\n",
    "right_on = input(\"Right on: \" )\n",
    "how = input(\"How: (‘left’, ‘right’, ‘outer’, ‘inner’) \" )\n",
    "\n",
    "merged_df = pd.merge(df, crosswalk, left_on=left_on, right_on=right_on, how=how)\n",
    "merged_df = merged_df.drop(left_on, axis=1)\n",
    "\n",
    "# Save the data\n",
    "# Save the data\n",
    "saveFile = input(\"Save File ('Y' or 'N'): \")\n",
    "if saveFile == 'Y' or saveFile == 'y':\n",
    "  outFile = input(\"Saved Filename (Do not include the file extension ): \")\n",
    "  merged_df.to_csv(outFile+'.csv', quoting=csv.QUOTE_ALL);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12255,
     "status": "aborted",
     "timestamp": 1615318970863,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "1pV4vUtlD1gM"
   },
   "outputs": [],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azqFNrQfD1gN"
   },
   "source": [
    "# Advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_zcgXJFhD1gN"
   },
   "source": [
    "For this next example to work, we will need to import hypothetical csv files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNNrqCbWD1gN"
   },
   "source": [
    "__Intro__\n",
    "\n",
    "The following Python function is a bulked out version of the previous notes. \n",
    "- It contains everything from the tutorial plus more.\n",
    "- It can be imported and used in future projects or stand alone.\n",
    "\n",
    "**Description:** add columns of data from a foreign dataset into a primary dataset along set parameters. \n",
    "\n",
    "**Purpose:** Makes Merging datasets simple\n",
    "\n",
    "__Services__\n",
    "\n",
    "- Merge two datasets without a crosswalk\n",
    "- Merge two datasets with a crosswalk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12254,
     "status": "aborted",
     "timestamp": 1615318970864,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "yZKhvR90D1gN"
   },
   "outputs": [],
   "source": [
    "#export\n",
    "#@ title Run: Create mergeDatasets()\n",
    "\n",
    "# Worried about infinit interactive-loops. not an issue atm.\n",
    "# Crosswalk needs to have exact same column names as left/right datasets\n",
    "\n",
    "def mergeDatasets(left_ds=False, right_ds=False, crosswalk_ds=False,\n",
    "                  left_col=False, right_col=False,\n",
    "                  crosswalk_left_col = False, crosswalk_right_col = False,\n",
    "                  merge_how=False, # left right or columnname to retrieve\n",
    "                  interactive=True):\n",
    "\n",
    "  if (interactive): print('\\n Loading Left Dataset');\n",
    "  left_ds, left_col = Intake.getAndCheck(left_ds, left_col, interactive)\n",
    "\n",
    "  if (interactive): print('\\n Loading Right Dataset');\n",
    "  right_ds, right_col  = Intake.getAndCheck(right_ds, right_col, interactive)\n",
    "\n",
    "  # 1. returns column or False\n",
    "  def checkMergeHow(right_ds, how, interactive):\n",
    "    inList = how in ['left', 'right', 'outer', 'inner']\n",
    "    inDf = Intake.getAndCheck(right_ds, how, False)\n",
    "    if ( inList or inDf ): return how\n",
    "    elif ( not interactive ): return False\n",
    "    else:\n",
    "      try:\n",
    "        print('\\n InValid Crosswalk Column Given. \\n Please select a value from either list');\n",
    "        print(\"\\n 1) Pull A single Column from the Right Dataset: \", right_ds.columns)\n",
    "        print(\"OR \\n 2) Join Operation: (‘left’, ‘right’, ‘outer’, ‘inner’, columnName) \" )\n",
    "        return checkMergeHow(right_ds, input(\"Column Name: \" ), interactive);\n",
    "      except: return False # User probably trying to escape interactivity\n",
    "\n",
    "  if (interactive): print('\\n Validating the merge_how Parameter');\n",
    "  merge_how = checkMergeHow(right_ds, merge_how, interactive)\n",
    "\n",
    "  # 2i. This will load our dataset if provided as a url. As well as coerce the dtypes for merging.\n",
    "  def coerceForMerge( msg, first_ds, second_ds, first_col, second_col, interactive ):\n",
    "      if (interactive):\n",
    "        print('\\n coerceForMerge: ' + msg);\n",
    "        print('cols : ', first_col, second_col)\n",
    "        print('BEFORE COERCE : ', first_ds[first_col].dtype, second_ds[second_col].dtypes)\n",
    "      second_ds, second_col = Intake.getAndCheck(second_ds, second_col, interactive)\n",
    "      first_ds, second_ds, status = Intake.coerce(first_ds, second_ds, first_col, second_col, interactive);\n",
    "      if (not status and interactive): print('\\n There was a problem!');\n",
    "      if (interactive):\n",
    "        print('AFTER COERCE', first_ds[first_col].dtype, second_ds[second_col].dtypes, second_col )\n",
    "      return first_ds, second_ds, second_col, status\n",
    "  # 2ii.\n",
    "  def mergeAndFilter(msg, first_ds, second_ds, first_col, second_col, how, interactive):\n",
    "      if interactive:\n",
    "        print('PERFORMING MERGE : '+ msg);\n",
    "        print('first_col : ', first_col, first_ds[first_col].dtype)\n",
    "        print('how: ', how)\n",
    "        print('second_col : ', second_col, second_ds[second_col].dtype)\n",
    "      first_ds = mergeOrPull(first_ds, second_ds, first_col, second_col, how)\n",
    "      return filterEmpties(first_ds, second_ds, first_col, second_col, how, interactive)\n",
    "\n",
    "  # Decide to perform a merge or commit a pull\n",
    "  def mergeOrPull(df, cw, left_on, right_on, how):\n",
    "\n",
    "    def merge(df, cw, left_on, right_on, how):\n",
    "      df = pd.merge(df, cw, left_on=left_on, right_on=right_on, how=how)\n",
    "      # df.drop(left_on, axis=1)\n",
    "      df[right_on] = df[right_on].fillna(value='empty')\n",
    "      return df\n",
    "\n",
    "    def pull(df, cw, left_on, right_on, how):\n",
    "      crswlk = dict(zip(cw[right_on], cw[how]  ) )\n",
    "      dtype = df[left_on].dtype\n",
    "      if dtype =='object':  df[how] = df.apply(lambda row: crswlk.get(str(row[left_on]), \"empty\"), axis=1)\n",
    "      elif dtype == 'int64':\n",
    "        df[how] = df.apply(lambda row: crswlk.get(int(row[left_on]), \"empty\"), axis=1)\n",
    "      return df\n",
    "\n",
    "    mergeType = how in ['left', 'right', 'outer', 'inner']\n",
    "    if mergeType: return merge(df, cw, left_on, right_on, how)\n",
    "    else: return pull(df, cw, left_on, right_on, how)\n",
    "\n",
    "  # 2iiii. Filter between matched records and not.\n",
    "  def filterEmpties(df, cw, left_on, right_on, how, interactive):\n",
    "\n",
    "    if how in ['left', 'right', 'outer', 'inner']: how = right_on\n",
    "    nomatch = df.loc[df[how] == 'empty']\n",
    "    nomatch = nomatch.sort_values(by=left_on, ascending=True)\n",
    "\n",
    "    if nomatch.shape[0] > 0:\n",
    "      # Do the same thing with our foreign tracts\n",
    "      if(interactive):\n",
    "        print('\\n Local Column Values Not Matched ')\n",
    "        print(nomatch[left_on].unique() )\n",
    "        print(len(nomatch[left_on]))\n",
    "        print('\\n Crosswalk Unique Column Values')\n",
    "        print(cw[right_on].unique() )\n",
    "\n",
    "    # Create a new column with the tracts value mapped to its corresponding value from the crossswalk\n",
    "    df[how].replace('empty', np.nan, inplace=True)\n",
    "    df.dropna(subset=[how], inplace=True)\n",
    "    # cw = cw.sort_values(by=how, ascending=True)\n",
    "    return df\n",
    "\n",
    "  # 2. If crosswalk check left-cw, right-cw. try coercing. return ds's, col's, and coerce status\n",
    "  def checkMerge(left_ds, right_ds, crosswalk_ds, left_col, right_col, crosswalk_left_col, crosswalk_right_col , interactive):\n",
    "    status = False\n",
    "    use_crosswalk = crosswalk_ds\n",
    "    if (interactive and not use_crosswalk):\n",
    "      use_crosswalk = input(\"\\n Import a crosswalk? ('True'/'False') \" ) == \"True\"\n",
    "      if (use_crosswalk): crosswalk_ds = input(\"crosswalk Url\" )\n",
    "    if (use_crosswalk):\n",
    "      if (interactive): print('\\n Loading Crosswalk... \\r\\n\\r\\n Left: ', crosswalk_left_col, ' Right: ', crosswalk_right_col, '\\n\\r\\n');\n",
    "      crosswalk_ds = Intake.getAndCheckDataset(crosswalk_ds, interactive)\n",
    "\n",
    "      left_ds, crosswalk_ds, crosswalk_left_col, status = coerceForMerge(\n",
    "        'Left-Crosswalk', left_ds, crosswalk_ds, left_col, crosswalk_left_col, interactive )\n",
    "\n",
    "      right_ds, crosswalk_ds, crosswalk_right_col, status = coerceForMerge(\n",
    "        'Right-Crosswalk',right_ds, crosswalk_ds, right_col, crosswalk_right_col, interactive )\n",
    "\n",
    "      if (interactive): print('\\n\\r\\n\\r End Crosswalk Update. Coerceing complete. Status: ', status, '\\n \\r\\n\\r\\n');\n",
    "    else:\n",
    "      left_ds, right_ds, right_col, status = coerceForMerge('Left-Right', left_ds, right_ds, left_col, right_col, interactive )\n",
    "    return left_ds, right_ds, crosswalk_ds, right_col, crosswalk_left_col, crosswalk_right_col, status\n",
    "\n",
    "  left_ds, right_ds, crosswalk_ds, right_col, crosswalk_left_col, crosswalk_right_col, status = checkMerge(\n",
    "      left_ds, right_ds, crosswalk_ds, left_col, right_col, crosswalk_left_col, crosswalk_right_col , interactive\n",
    "  )\n",
    "\n",
    "  if ( not status ):\n",
    "    if (interactive):print('\\n Was not able to complete merge!');\n",
    "    return False;\n",
    "  else:\n",
    "    if (not type( crosswalk_ds ) == bool):\n",
    "      left_ds = mergeAndFilter('LEFT->CROSSWALK', left_ds, crosswalk_ds, left_col, crosswalk_left_col, crosswalk_right_col, interactive)\n",
    "      left_col = crosswalk_right_col\n",
    "    left_ds = mergeAndFilter('LEFT->RIGHT', left_ds, right_ds, left_col, right_col, merge_how, interactive)\n",
    "  return left_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zTiCdAL3D1gN"
   },
   "source": [
    "### Function Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oczVlOmwD1gO"
   },
   "source": [
    "**Input(s):** \n",
    "- Dataset url\n",
    "- Crosswalk Url \n",
    "- Right On \n",
    "- Left On \n",
    "- How \n",
    "- New Filename \n",
    "\n",
    "**Output:** File\n",
    "\n",
    "**How it works:**\n",
    "- Read in datasets\n",
    "- Perform Merge\n",
    "\n",
    "- If the 'how' parameter is equal to ['left', 'right', 'outer', 'inner']\n",
    "- - then a merge will be performed. \n",
    "- If a column name is provided in the 'how' parameter\n",
    "- - then that single column will be pulled from the right dataset as a new column in the left_ds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfRGJq1OD1gR"
   },
   "source": [
    "## Function Diagrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6Zp3BZ3D1gS"
   },
   "source": [
    "Diagram the mergeDatasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12242,
     "status": "aborted",
     "timestamp": 1615318970867,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "1ga0ZXeWD1gS"
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<img src=\"https://bniajfi.org/images/mermaid/class_diagram_merge_datasets.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_DslMrrD1gS"
   },
   "source": [
    "mergeDatasets Flow Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12227,
     "status": "aborted",
     "timestamp": 1615318970869,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "eHerXET2D1gS"
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<img src=\"https://bniajfi.org/images/mermaid/flow_chart_merge_datasets.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QlHUiKg3D1gS"
   },
   "source": [
    "Gannt Chart  mergeDatasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12210,
     "status": "aborted",
     "timestamp": 1615318970869,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "wutM4dfTD1gT"
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<img src=\"https://bniajfi.org/images/mermaid/gannt_chart_merge_datasets.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z99f92rKD1gT"
   },
   "source": [
    "Sequence Diagram  mergeDatasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12196,
     "status": "aborted",
     "timestamp": 1615318970870,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "bhbpyylSD1gT"
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<img src=\"https://bniajfi.org/images/mermaid/sequence_diagram_merge_datasets.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQ43Mk9YD1gT"
   },
   "source": [
    "## Function Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_AY1AnswD1gT"
   },
   "source": [
    "#### Interactive Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12194,
     "status": "aborted",
     "timestamp": 1615318970871,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "Omv9OnKaD1gT"
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from dataplay.geoms import readInGeometryData \r\n",
    "Hhchpov = gpd.read_file(\"https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhchpov/FeatureServer/1/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\")\r\n",
    "Hhchpov = Hhchpov[['CSA2010', 'hhchpov15',\t'hhchpov16',\t'hhchpov17',\t'hhchpov18']]\r\n",
    "Hhchpov.to_csv('Hhchpov.csv')\r\n",
    "\r\n",
    "Hhpov = gpd.read_file(\"https://services1.arcgis.com/mVFRs7NF4iFitgbY/ArcGIS/rest/services/Hhpov/FeatureServer/1/query?where=1%3D1&outFields=*&returnGeometry=true&f=pgeojson\")\r\n",
    "Hhpov = Hhpov[['CSA2010', 'hhpov15',\t'hhpov16',\t'hhpov17',\t'hhpov18']]\r\n",
    "Hhpov.to_csv('Hhpov.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12181,
     "status": "aborted",
     "timestamp": 1615318970871,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "BwjdpUTDD1gU"
   },
   "outputs": [],
   "source": [
    "Hhchpov.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12167,
     "status": "aborted",
     "timestamp": 1615318970872,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "Ct8rupgPD1gU"
   },
   "outputs": [],
   "source": [
    "Hhpov.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12155,
     "status": "aborted",
     "timestamp": 1615318970873,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "DwEDup6WD1gU"
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12146,
     "status": "aborted",
     "timestamp": 1615318970874,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "YvbacQjDD1gU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import geopandas as gpd\r\n",
    "# Table: FDIC Baltimore Banks\r\n",
    "# Columns: Bank Name, Address(es), Census Tract\r\n",
    "left_ds = 'Hhpov.csv'\r\n",
    "left_col = 'CSA2010'\r\n",
    "\r\n",
    "# Table: Crosswalk Census Communities\r\n",
    "# 'TRACT2010', 'GEOID2010', 'CSA2010'\r\n",
    "right_ds = 'Hhchpov.csv'\r\n",
    "right_col='CSA2010'\r\n",
    "\r\n",
    "merge_how = 'outer'\r\n",
    "interactive = True\r\n",
    "\r\n",
    "merged_df = mergeDatasets(left_ds=left_ds, right_ds=right_ds, crosswalk_ds=False,\r\n",
    "                  left_col=left_col, right_col=right_col,\r\n",
    "                  crosswalk_left_col = False, crosswalk_right_col = False,\r\n",
    "                  merge_how=merge_how, # left right or columnname to retrieve\r\n",
    "                  interactive=True)\r\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12135,
     "status": "aborted",
     "timestamp": 1615318970875,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "KICmm3IxD1gU"
   },
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3qKnupuD1gV"
   },
   "source": [
    "#### Example 2 ) Get CSA and Geometry with a Crosswalk using 3 links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12134,
     "status": "aborted",
     "timestamp": 1615318970876,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "QNJqsCCUD1gV"
   },
   "outputs": [],
   "source": [
    "# Primary Table\n",
    "# Description: I created a public dataset from a google xlsx sheet 'Bank Addresses and Census Tract' from a workbook of the same name.\n",
    "# Table: FDIC Baltimore Banks\n",
    "# Columns: Bank Name, Address(es), Census Tract\n",
    "left_ds = 'https28768&single=true&output=csv'\n",
    "left_col = 'Census Tract'\n",
    "\n",
    "# Alternate Primary Table\n",
    "# Description: Same workbook, different Sheet: 'Branches per tract' \n",
    "# Columns: Census Tract, Number branches per tract\n",
    "# left_ds = 'https://docssingle=true&output=csv'\n",
    "# lef_col = 'Number branches per tract'\n",
    "\n",
    "# Crosswalk Table\n",
    "# Table: Crosswalk Census Communities\n",
    "# 'TRACT2010', 'GEOID2010', 'CSA2010'\n",
    "crosswalk_ds = 'https://docs.goot=csv'\n",
    "use_crosswalk = True\n",
    "crosswalk_left_col = 'TRACT2010'\n",
    "crosswalk_right_col = 'GEOID2010'\n",
    "\n",
    "# Secondary Table\n",
    "# Table: Baltimore Boundaries\n",
    "# 'TRACTCE10', 'GEOID10', 'CSA', 'NAME10', 'Tract', 'geometry'\n",
    "right_ds = 'httpse=true&output=csv'\n",
    "right_col ='GEOID10'\n",
    "\n",
    "merge_how = 'geometry'\n",
    "interactive = True\n",
    "merge_how = 'outer'\n",
    "\n",
    "merged_df_geom = mergeDatasets(left_ds=left_ds, right_ds=right_ds, crosswalk_ds=False,\n",
    "                  left_col=left_col, right_col=right_col,\n",
    "                  crosswalk_left_col = False, crosswalk_right_col = False,\n",
    "                  merge_how=merge_how, # left right or columnname to retrieve\n",
    "                  interactive=True)\n",
    "\n",
    "merged_df_geom.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQ2LnN1UD1gV"
   },
   "source": [
    "Here we can save the data so that it may be used in later tutorials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12133,
     "status": "aborted",
     "timestamp": 1615318970876,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "phSfipCKD1gV"
   },
   "outputs": [],
   "source": [
    "string = 'test_save_data_with_geom_and_csa'\n",
    "merged_df.to_csv(string+'.csv', encoding=\"utf-8\", index=False, quoting=csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6CQWMMaD1gV"
   },
   "source": [
    "#### Example 3: Ran Alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12133,
     "status": "aborted",
     "timestamp": 1615318970878,
     "user": {
      "displayName": "Charles Karpati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiQg4PIuuYRyIyCWtHJXvMzkkkBSQpEzUYL20Bjog=s64",
      "userId": "06248540216665543849"
     },
     "user_tz": 300
    },
    "id": "4hPilfvkD1gV"
   },
   "outputs": [],
   "source": [
    "mergeDatasets()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "02_Merge_Data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
