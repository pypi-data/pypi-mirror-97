# This file was automatically generated by SWIG (http://www.swig.org).
# Version 4.0.2
#
# Do not make changes to this file unless you know what you are doing--modify
# the SWIG interface file instead.


import collections

from sys import version_info as _version_info
if _version_info < (3, 6, 0):
    raise RuntimeError("Python 3.6 or later required")


from . import _ITKWatershedsPython



from sys import version_info as _swig_python_version_info
if _swig_python_version_info < (2, 7, 0):
    raise RuntimeError("Python 2.7 or later required")

# Import the low-level C/C++ module
if __package__ or "." in __name__:
    from . import _itkWatershedImageFilterPython
else:
    import _itkWatershedImageFilterPython

try:
    import builtins as __builtin__
except ImportError:
    import __builtin__

_swig_new_instance_method = _itkWatershedImageFilterPython.SWIG_PyInstanceMethod_New
_swig_new_static_method = _itkWatershedImageFilterPython.SWIG_PyStaticMethod_New

def _swig_repr(self):
    try:
        strthis = "proxy of " + self.this.__repr__()
    except __builtin__.Exception:
        strthis = ""
    return "<%s.%s; %s >" % (self.__class__.__module__, self.__class__.__name__, strthis,)


def _swig_setattr_nondynamic_instance_variable(set):
    def set_instance_attr(self, name, value):
        if name == "thisown":
            self.this.own(value)
        elif name == "this":
            set(self, name, value)
        elif hasattr(self, name) and isinstance(getattr(type(self), name), property):
            set(self, name, value)
        else:
            raise AttributeError("You cannot add instance attributes to %s" % self)
    return set_instance_attr


def _swig_setattr_nondynamic_class_variable(set):
    def set_class_attr(cls, name, value):
        if hasattr(cls, name) and not isinstance(getattr(cls, name), property):
            set(cls, name, value)
        else:
            raise AttributeError("You cannot add class attributes to %s" % cls)
    return set_class_attr


def _swig_add_metaclass(metaclass):
    """Class decorator for adding a metaclass to a SWIG wrapped class - a slimmed down version of six.add_metaclass"""
    def wrapper(cls):
        return metaclass(cls.__name__, cls.__bases__, cls.__dict__.copy())
    return wrapper


class _SwigNonDynamicMeta(type):
    """Meta class to enforce nondynamic attributes (no new attributes) for a class"""
    __setattr__ = _swig_setattr_nondynamic_class_variable(type.__setattr__)


import collections.abc
import itk.ITKCommonBasePython
import itk.pyBasePython
import itk.itkImagePython
import itk.itkImageRegionPython
import itk.itkSizePython
import itk.itkIndexPython
import itk.itkOffsetPython
import itk.itkMatrixPython
import itk.vnl_vectorPython
import itk.vnl_matrixPython
import itk.stdcomplexPython
import itk.vnl_matrix_fixedPython
import itk.itkVectorPython
import itk.itkFixedArrayPython
import itk.vnl_vector_refPython
import itk.itkPointPython
import itk.itkCovariantVectorPython
import itk.itkRGBPixelPython
import itk.itkSymmetricSecondRankTensorPython
import itk.itkRGBAPixelPython
import itk.itkImageToImageFilterAPython
import itk.itkImageToImageFilterCommonPython
import itk.itkImageSourcePython
import itk.itkImageSourceCommonPython
import itk.itkVectorImagePython
import itk.itkVariableLengthVectorPython

def itkWatershedImageFilterID2_New():
    return itkWatershedImageFilterID2.New()

class itkWatershedImageFilterID2(itk.itkImageToImageFilterAPython.itkImageToImageFilterID2IUL2):
    r"""


    A low-level image analysis algorithm that automatically produces a
    hierarchy of segmented, labeled images from a scalar-valued image
    input.

    Overview and terminology

    This filter implements a non-streaming version of an image
    segmentation algorithm commonly known as "watershed segmentation".
    Watershed segmentation gets its name from the manner in which the
    algorithm segments regions into catchment basins. If a function $ f $
    is a continuous height function defined over an image domain, then a
    catchment basin is defined as the set of points whose paths of
    steepest descent terminate at the same local minimum of $ f $.

    The choice of height function (input) depends on the application, and
    the basic watershed algorithm operates independently of that choice.
    For intensity-based image data, you might typically use some sort of
    gradient magnitude calculation as input. (see
    itk::GradientMagnitudeImageFilter)

    The watershed algorithm proceeds in several steps. First, an initial
    classification of all points into catchment basin regions is done by
    tracing each point down its path of steepest descent to a local
    minima. Next, neighboring regions and the boundaries between them are
    analyzed according to some saliency measure (such as minimum boundary
    height) to produce a tree of merges among adjacent regions. These
    merges occur at different maximum saliency values. The collective set
    of all possible merges up to a specified saliency "flood level" is
    referred to in this documentation as a "merge tree". Metaphorically,
    the flood level is a value that reflects the amount of precipitation
    that is rained into the catchment basins. As the flood level rises,
    boundaries between adjacent segments erode and those segments merge.
    The minimum value of the flood level is zero and the maximum value is
    the difference between the highest and lowest values in the input
    image.

    Note that once the initial analysis and segmentation is done to
    produce the merge tree, it is trivial to produce a hierarchy of
    labeled images in constant time. The complexity of the algorithm is in
    the computation of the merge tree. Once that tree has been created,
    the initial segmented image can be relabeled to reflect any maximum
    saliency value found in the tree by simply identifying a subset of
    segment merges from the tree. Implementational details This filter is
    a wrapper for several lower level process objects (watershed algorithm
    components in the namespace "watershed"). For a more complete
    picture of the implementation, refer to the documentation of those
    components. The component classes were designed to operate in either a
    data-streaming or a non-data-streaming mode. The pipeline constructed
    in this class' GenerateData() method does not support streaming, but
    is the common use case for the components. Description of the input to
    this filter The input to this filter is a scalar itk::Image of any
    dimensionality. This input image is assumed to represent some sort of
    height function or edge map based on the original image that you want
    to segment (such as would be produced by
    itk::GradientMagnitudeImageFilter). This filter does not do any pre-
    processing on its input other than a thresholding step. The algorithm
    does not explicitly require that the input be of any particular data
    type, but floating point or double precision data is recommended.

    The recommended pre-processing for scalar image input to this
    algorithm is to use one of the itk::AnisotropicDiffusionImageFilter
    subclasses to smooth the original image and then perform some sort of
    edge calculation based on gradients or curvature. Description of the
    output of this filter This filter will produce an itk::Image of
    IdentifierType integer type and of the same dimensionality as the
    input image. The IdentifierType output image is referred to as the
    "labeled image" in this documentation. Each pixel in the image is
    assigned an IdentifierType integer label that groups it within a
    connected region. Some notes on filter parameters Two parameters
    control the output of this filter, Threshold and Level. The units of
    both parameters are percentage points of the maximum height value in
    the input.

    Threshold is used to set the absolute minimum height value used during
    processing. Raising this threshold percentage effectively decreases
    the number of local minima in the input, resulting in an initial
    segmentation with fewer regions. The assumption is that the shallow
    regions that thresholding removes are of of less interest.

    The Level parameter controls the depth of metaphorical flooding of the
    image. That is, it sets the maximum saliency value of interest in the
    result. Raising and lowering the Level influences the number of
    segments in the basic segmentation that are merged to produce the
    final output. A level of 1.0 is analogous to flooding the image up to
    a depth that is 100 percent of the maximum value in the image. A level
    of 0.0 produces the basic segmentation, which will typically be very
    oversegmented. Level values of interest are typically low (i.e. less
    than about 0.40 or 40% ), since higher values quickly start to
    undersegment the image.

    The Level parameter can be used to create a hierarchy of output images
    in constant time once an initial segmentation is done. A typical
    scenario might go like this: For the initial execution of the filter,
    set the Level to the maximum saliency value that you anticipate might
    be of interest. Once the initial Update() of this process object has
    finished, the Level can be manipulated anywhere below the initial
    setting without triggering a full update of the segmentation mini-
    pipeline. All that is now be required to produce the new output is a
    simple relabeling of the output image.

    Threshold and Level parameters are controlled through the class'
    Get/SetThreshold() and Get/SetLevel() methods.
    example{Segmentation/Watersheds/SegmentWithWatershedImageFilter,Wa
    tershed Image Filter} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID2___New_orig__)
    Clone = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID2_Clone)
    GenerateData = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID2_GenerateData)
    SetInput = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID2_SetInput)
    SetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID2_SetThreshold)
    GetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID2_GetThreshold)
    SetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID2_SetLevel)
    GetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID2_GetLevel)
    GetBasicSegmentation = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID2_GetBasicSegmentation)
    GetSegmentTree = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID2_GetSegmentTree)
    InputEqualityComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterID2_InputEqualityComparableCheck
    
    InputAdditiveOperatorsCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterID2_InputAdditiveOperatorsCheck
    
    DoubleInputMultiplyOperatorCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterID2_DoubleInputMultiplyOperatorCheck
    
    InputLessThanComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterID2_InputLessThanComparableCheck
    
    __swig_destroy__ = _itkWatershedImageFilterPython.delete_itkWatershedImageFilterID2
    cast = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID2_cast)

    def New(*args, **kargs):
        """New() -> itkWatershedImageFilterID2

        Create a new object of the class itkWatershedImageFilterID2 and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkWatershedImageFilterID2.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkWatershedImageFilterID2.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkWatershedImageFilterID2.__New_orig__()
        from itk.support import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkWatershedImageFilterID2 in _itkWatershedImageFilterPython:
_itkWatershedImageFilterPython.itkWatershedImageFilterID2_swigregister(itkWatershedImageFilterID2)
itkWatershedImageFilterID2___New_orig__ = _itkWatershedImageFilterPython.itkWatershedImageFilterID2___New_orig__
itkWatershedImageFilterID2_cast = _itkWatershedImageFilterPython.itkWatershedImageFilterID2_cast


def itkWatershedImageFilterID3_New():
    return itkWatershedImageFilterID3.New()

class itkWatershedImageFilterID3(itk.itkImageToImageFilterAPython.itkImageToImageFilterID3IUL3):
    r"""


    A low-level image analysis algorithm that automatically produces a
    hierarchy of segmented, labeled images from a scalar-valued image
    input.

    Overview and terminology

    This filter implements a non-streaming version of an image
    segmentation algorithm commonly known as "watershed segmentation".
    Watershed segmentation gets its name from the manner in which the
    algorithm segments regions into catchment basins. If a function $ f $
    is a continuous height function defined over an image domain, then a
    catchment basin is defined as the set of points whose paths of
    steepest descent terminate at the same local minimum of $ f $.

    The choice of height function (input) depends on the application, and
    the basic watershed algorithm operates independently of that choice.
    For intensity-based image data, you might typically use some sort of
    gradient magnitude calculation as input. (see
    itk::GradientMagnitudeImageFilter)

    The watershed algorithm proceeds in several steps. First, an initial
    classification of all points into catchment basin regions is done by
    tracing each point down its path of steepest descent to a local
    minima. Next, neighboring regions and the boundaries between them are
    analyzed according to some saliency measure (such as minimum boundary
    height) to produce a tree of merges among adjacent regions. These
    merges occur at different maximum saliency values. The collective set
    of all possible merges up to a specified saliency "flood level" is
    referred to in this documentation as a "merge tree". Metaphorically,
    the flood level is a value that reflects the amount of precipitation
    that is rained into the catchment basins. As the flood level rises,
    boundaries between adjacent segments erode and those segments merge.
    The minimum value of the flood level is zero and the maximum value is
    the difference between the highest and lowest values in the input
    image.

    Note that once the initial analysis and segmentation is done to
    produce the merge tree, it is trivial to produce a hierarchy of
    labeled images in constant time. The complexity of the algorithm is in
    the computation of the merge tree. Once that tree has been created,
    the initial segmented image can be relabeled to reflect any maximum
    saliency value found in the tree by simply identifying a subset of
    segment merges from the tree. Implementational details This filter is
    a wrapper for several lower level process objects (watershed algorithm
    components in the namespace "watershed"). For a more complete
    picture of the implementation, refer to the documentation of those
    components. The component classes were designed to operate in either a
    data-streaming or a non-data-streaming mode. The pipeline constructed
    in this class' GenerateData() method does not support streaming, but
    is the common use case for the components. Description of the input to
    this filter The input to this filter is a scalar itk::Image of any
    dimensionality. This input image is assumed to represent some sort of
    height function or edge map based on the original image that you want
    to segment (such as would be produced by
    itk::GradientMagnitudeImageFilter). This filter does not do any pre-
    processing on its input other than a thresholding step. The algorithm
    does not explicitly require that the input be of any particular data
    type, but floating point or double precision data is recommended.

    The recommended pre-processing for scalar image input to this
    algorithm is to use one of the itk::AnisotropicDiffusionImageFilter
    subclasses to smooth the original image and then perform some sort of
    edge calculation based on gradients or curvature. Description of the
    output of this filter This filter will produce an itk::Image of
    IdentifierType integer type and of the same dimensionality as the
    input image. The IdentifierType output image is referred to as the
    "labeled image" in this documentation. Each pixel in the image is
    assigned an IdentifierType integer label that groups it within a
    connected region. Some notes on filter parameters Two parameters
    control the output of this filter, Threshold and Level. The units of
    both parameters are percentage points of the maximum height value in
    the input.

    Threshold is used to set the absolute minimum height value used during
    processing. Raising this threshold percentage effectively decreases
    the number of local minima in the input, resulting in an initial
    segmentation with fewer regions. The assumption is that the shallow
    regions that thresholding removes are of of less interest.

    The Level parameter controls the depth of metaphorical flooding of the
    image. That is, it sets the maximum saliency value of interest in the
    result. Raising and lowering the Level influences the number of
    segments in the basic segmentation that are merged to produce the
    final output. A level of 1.0 is analogous to flooding the image up to
    a depth that is 100 percent of the maximum value in the image. A level
    of 0.0 produces the basic segmentation, which will typically be very
    oversegmented. Level values of interest are typically low (i.e. less
    than about 0.40 or 40% ), since higher values quickly start to
    undersegment the image.

    The Level parameter can be used to create a hierarchy of output images
    in constant time once an initial segmentation is done. A typical
    scenario might go like this: For the initial execution of the filter,
    set the Level to the maximum saliency value that you anticipate might
    be of interest. Once the initial Update() of this process object has
    finished, the Level can be manipulated anywhere below the initial
    setting without triggering a full update of the segmentation mini-
    pipeline. All that is now be required to produce the new output is a
    simple relabeling of the output image.

    Threshold and Level parameters are controlled through the class'
    Get/SetThreshold() and Get/SetLevel() methods.
    example{Segmentation/Watersheds/SegmentWithWatershedImageFilter,Wa
    tershed Image Filter} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID3___New_orig__)
    Clone = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID3_Clone)
    GenerateData = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID3_GenerateData)
    SetInput = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID3_SetInput)
    SetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID3_SetThreshold)
    GetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID3_GetThreshold)
    SetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID3_SetLevel)
    GetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID3_GetLevel)
    GetBasicSegmentation = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID3_GetBasicSegmentation)
    GetSegmentTree = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID3_GetSegmentTree)
    InputEqualityComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterID3_InputEqualityComparableCheck
    
    InputAdditiveOperatorsCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterID3_InputAdditiveOperatorsCheck
    
    DoubleInputMultiplyOperatorCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterID3_DoubleInputMultiplyOperatorCheck
    
    InputLessThanComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterID3_InputLessThanComparableCheck
    
    __swig_destroy__ = _itkWatershedImageFilterPython.delete_itkWatershedImageFilterID3
    cast = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID3_cast)

    def New(*args, **kargs):
        """New() -> itkWatershedImageFilterID3

        Create a new object of the class itkWatershedImageFilterID3 and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkWatershedImageFilterID3.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkWatershedImageFilterID3.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkWatershedImageFilterID3.__New_orig__()
        from itk.support import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkWatershedImageFilterID3 in _itkWatershedImageFilterPython:
_itkWatershedImageFilterPython.itkWatershedImageFilterID3_swigregister(itkWatershedImageFilterID3)
itkWatershedImageFilterID3___New_orig__ = _itkWatershedImageFilterPython.itkWatershedImageFilterID3___New_orig__
itkWatershedImageFilterID3_cast = _itkWatershedImageFilterPython.itkWatershedImageFilterID3_cast


def itkWatershedImageFilterID4_New():
    return itkWatershedImageFilterID4.New()

class itkWatershedImageFilterID4(itk.itkImageToImageFilterAPython.itkImageToImageFilterID4IUL4):
    r"""


    A low-level image analysis algorithm that automatically produces a
    hierarchy of segmented, labeled images from a scalar-valued image
    input.

    Overview and terminology

    This filter implements a non-streaming version of an image
    segmentation algorithm commonly known as "watershed segmentation".
    Watershed segmentation gets its name from the manner in which the
    algorithm segments regions into catchment basins. If a function $ f $
    is a continuous height function defined over an image domain, then a
    catchment basin is defined as the set of points whose paths of
    steepest descent terminate at the same local minimum of $ f $.

    The choice of height function (input) depends on the application, and
    the basic watershed algorithm operates independently of that choice.
    For intensity-based image data, you might typically use some sort of
    gradient magnitude calculation as input. (see
    itk::GradientMagnitudeImageFilter)

    The watershed algorithm proceeds in several steps. First, an initial
    classification of all points into catchment basin regions is done by
    tracing each point down its path of steepest descent to a local
    minima. Next, neighboring regions and the boundaries between them are
    analyzed according to some saliency measure (such as minimum boundary
    height) to produce a tree of merges among adjacent regions. These
    merges occur at different maximum saliency values. The collective set
    of all possible merges up to a specified saliency "flood level" is
    referred to in this documentation as a "merge tree". Metaphorically,
    the flood level is a value that reflects the amount of precipitation
    that is rained into the catchment basins. As the flood level rises,
    boundaries between adjacent segments erode and those segments merge.
    The minimum value of the flood level is zero and the maximum value is
    the difference between the highest and lowest values in the input
    image.

    Note that once the initial analysis and segmentation is done to
    produce the merge tree, it is trivial to produce a hierarchy of
    labeled images in constant time. The complexity of the algorithm is in
    the computation of the merge tree. Once that tree has been created,
    the initial segmented image can be relabeled to reflect any maximum
    saliency value found in the tree by simply identifying a subset of
    segment merges from the tree. Implementational details This filter is
    a wrapper for several lower level process objects (watershed algorithm
    components in the namespace "watershed"). For a more complete
    picture of the implementation, refer to the documentation of those
    components. The component classes were designed to operate in either a
    data-streaming or a non-data-streaming mode. The pipeline constructed
    in this class' GenerateData() method does not support streaming, but
    is the common use case for the components. Description of the input to
    this filter The input to this filter is a scalar itk::Image of any
    dimensionality. This input image is assumed to represent some sort of
    height function or edge map based on the original image that you want
    to segment (such as would be produced by
    itk::GradientMagnitudeImageFilter). This filter does not do any pre-
    processing on its input other than a thresholding step. The algorithm
    does not explicitly require that the input be of any particular data
    type, but floating point or double precision data is recommended.

    The recommended pre-processing for scalar image input to this
    algorithm is to use one of the itk::AnisotropicDiffusionImageFilter
    subclasses to smooth the original image and then perform some sort of
    edge calculation based on gradients or curvature. Description of the
    output of this filter This filter will produce an itk::Image of
    IdentifierType integer type and of the same dimensionality as the
    input image. The IdentifierType output image is referred to as the
    "labeled image" in this documentation. Each pixel in the image is
    assigned an IdentifierType integer label that groups it within a
    connected region. Some notes on filter parameters Two parameters
    control the output of this filter, Threshold and Level. The units of
    both parameters are percentage points of the maximum height value in
    the input.

    Threshold is used to set the absolute minimum height value used during
    processing. Raising this threshold percentage effectively decreases
    the number of local minima in the input, resulting in an initial
    segmentation with fewer regions. The assumption is that the shallow
    regions that thresholding removes are of of less interest.

    The Level parameter controls the depth of metaphorical flooding of the
    image. That is, it sets the maximum saliency value of interest in the
    result. Raising and lowering the Level influences the number of
    segments in the basic segmentation that are merged to produce the
    final output. A level of 1.0 is analogous to flooding the image up to
    a depth that is 100 percent of the maximum value in the image. A level
    of 0.0 produces the basic segmentation, which will typically be very
    oversegmented. Level values of interest are typically low (i.e. less
    than about 0.40 or 40% ), since higher values quickly start to
    undersegment the image.

    The Level parameter can be used to create a hierarchy of output images
    in constant time once an initial segmentation is done. A typical
    scenario might go like this: For the initial execution of the filter,
    set the Level to the maximum saliency value that you anticipate might
    be of interest. Once the initial Update() of this process object has
    finished, the Level can be manipulated anywhere below the initial
    setting without triggering a full update of the segmentation mini-
    pipeline. All that is now be required to produce the new output is a
    simple relabeling of the output image.

    Threshold and Level parameters are controlled through the class'
    Get/SetThreshold() and Get/SetLevel() methods.
    example{Segmentation/Watersheds/SegmentWithWatershedImageFilter,Wa
    tershed Image Filter} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID4___New_orig__)
    Clone = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID4_Clone)
    GenerateData = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID4_GenerateData)
    SetInput = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID4_SetInput)
    SetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID4_SetThreshold)
    GetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID4_GetThreshold)
    SetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID4_SetLevel)
    GetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID4_GetLevel)
    GetBasicSegmentation = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID4_GetBasicSegmentation)
    GetSegmentTree = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID4_GetSegmentTree)
    InputEqualityComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterID4_InputEqualityComparableCheck
    
    InputAdditiveOperatorsCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterID4_InputAdditiveOperatorsCheck
    
    DoubleInputMultiplyOperatorCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterID4_DoubleInputMultiplyOperatorCheck
    
    InputLessThanComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterID4_InputLessThanComparableCheck
    
    __swig_destroy__ = _itkWatershedImageFilterPython.delete_itkWatershedImageFilterID4
    cast = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterID4_cast)

    def New(*args, **kargs):
        """New() -> itkWatershedImageFilterID4

        Create a new object of the class itkWatershedImageFilterID4 and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkWatershedImageFilterID4.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkWatershedImageFilterID4.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkWatershedImageFilterID4.__New_orig__()
        from itk.support import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkWatershedImageFilterID4 in _itkWatershedImageFilterPython:
_itkWatershedImageFilterPython.itkWatershedImageFilterID4_swigregister(itkWatershedImageFilterID4)
itkWatershedImageFilterID4___New_orig__ = _itkWatershedImageFilterPython.itkWatershedImageFilterID4___New_orig__
itkWatershedImageFilterID4_cast = _itkWatershedImageFilterPython.itkWatershedImageFilterID4_cast


def itkWatershedImageFilterIF2_New():
    return itkWatershedImageFilterIF2.New()

class itkWatershedImageFilterIF2(itk.itkImageToImageFilterAPython.itkImageToImageFilterIF2IUL2):
    r"""


    A low-level image analysis algorithm that automatically produces a
    hierarchy of segmented, labeled images from a scalar-valued image
    input.

    Overview and terminology

    This filter implements a non-streaming version of an image
    segmentation algorithm commonly known as "watershed segmentation".
    Watershed segmentation gets its name from the manner in which the
    algorithm segments regions into catchment basins. If a function $ f $
    is a continuous height function defined over an image domain, then a
    catchment basin is defined as the set of points whose paths of
    steepest descent terminate at the same local minimum of $ f $.

    The choice of height function (input) depends on the application, and
    the basic watershed algorithm operates independently of that choice.
    For intensity-based image data, you might typically use some sort of
    gradient magnitude calculation as input. (see
    itk::GradientMagnitudeImageFilter)

    The watershed algorithm proceeds in several steps. First, an initial
    classification of all points into catchment basin regions is done by
    tracing each point down its path of steepest descent to a local
    minima. Next, neighboring regions and the boundaries between them are
    analyzed according to some saliency measure (such as minimum boundary
    height) to produce a tree of merges among adjacent regions. These
    merges occur at different maximum saliency values. The collective set
    of all possible merges up to a specified saliency "flood level" is
    referred to in this documentation as a "merge tree". Metaphorically,
    the flood level is a value that reflects the amount of precipitation
    that is rained into the catchment basins. As the flood level rises,
    boundaries between adjacent segments erode and those segments merge.
    The minimum value of the flood level is zero and the maximum value is
    the difference between the highest and lowest values in the input
    image.

    Note that once the initial analysis and segmentation is done to
    produce the merge tree, it is trivial to produce a hierarchy of
    labeled images in constant time. The complexity of the algorithm is in
    the computation of the merge tree. Once that tree has been created,
    the initial segmented image can be relabeled to reflect any maximum
    saliency value found in the tree by simply identifying a subset of
    segment merges from the tree. Implementational details This filter is
    a wrapper for several lower level process objects (watershed algorithm
    components in the namespace "watershed"). For a more complete
    picture of the implementation, refer to the documentation of those
    components. The component classes were designed to operate in either a
    data-streaming or a non-data-streaming mode. The pipeline constructed
    in this class' GenerateData() method does not support streaming, but
    is the common use case for the components. Description of the input to
    this filter The input to this filter is a scalar itk::Image of any
    dimensionality. This input image is assumed to represent some sort of
    height function or edge map based on the original image that you want
    to segment (such as would be produced by
    itk::GradientMagnitudeImageFilter). This filter does not do any pre-
    processing on its input other than a thresholding step. The algorithm
    does not explicitly require that the input be of any particular data
    type, but floating point or double precision data is recommended.

    The recommended pre-processing for scalar image input to this
    algorithm is to use one of the itk::AnisotropicDiffusionImageFilter
    subclasses to smooth the original image and then perform some sort of
    edge calculation based on gradients or curvature. Description of the
    output of this filter This filter will produce an itk::Image of
    IdentifierType integer type and of the same dimensionality as the
    input image. The IdentifierType output image is referred to as the
    "labeled image" in this documentation. Each pixel in the image is
    assigned an IdentifierType integer label that groups it within a
    connected region. Some notes on filter parameters Two parameters
    control the output of this filter, Threshold and Level. The units of
    both parameters are percentage points of the maximum height value in
    the input.

    Threshold is used to set the absolute minimum height value used during
    processing. Raising this threshold percentage effectively decreases
    the number of local minima in the input, resulting in an initial
    segmentation with fewer regions. The assumption is that the shallow
    regions that thresholding removes are of of less interest.

    The Level parameter controls the depth of metaphorical flooding of the
    image. That is, it sets the maximum saliency value of interest in the
    result. Raising and lowering the Level influences the number of
    segments in the basic segmentation that are merged to produce the
    final output. A level of 1.0 is analogous to flooding the image up to
    a depth that is 100 percent of the maximum value in the image. A level
    of 0.0 produces the basic segmentation, which will typically be very
    oversegmented. Level values of interest are typically low (i.e. less
    than about 0.40 or 40% ), since higher values quickly start to
    undersegment the image.

    The Level parameter can be used to create a hierarchy of output images
    in constant time once an initial segmentation is done. A typical
    scenario might go like this: For the initial execution of the filter,
    set the Level to the maximum saliency value that you anticipate might
    be of interest. Once the initial Update() of this process object has
    finished, the Level can be manipulated anywhere below the initial
    setting without triggering a full update of the segmentation mini-
    pipeline. All that is now be required to produce the new output is a
    simple relabeling of the output image.

    Threshold and Level parameters are controlled through the class'
    Get/SetThreshold() and Get/SetLevel() methods.
    example{Segmentation/Watersheds/SegmentWithWatershedImageFilter,Wa
    tershed Image Filter} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF2___New_orig__)
    Clone = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF2_Clone)
    GenerateData = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF2_GenerateData)
    SetInput = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF2_SetInput)
    SetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF2_SetThreshold)
    GetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF2_GetThreshold)
    SetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF2_SetLevel)
    GetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF2_GetLevel)
    GetBasicSegmentation = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF2_GetBasicSegmentation)
    GetSegmentTree = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF2_GetSegmentTree)
    InputEqualityComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIF2_InputEqualityComparableCheck
    
    InputAdditiveOperatorsCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIF2_InputAdditiveOperatorsCheck
    
    DoubleInputMultiplyOperatorCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIF2_DoubleInputMultiplyOperatorCheck
    
    InputLessThanComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIF2_InputLessThanComparableCheck
    
    __swig_destroy__ = _itkWatershedImageFilterPython.delete_itkWatershedImageFilterIF2
    cast = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF2_cast)

    def New(*args, **kargs):
        """New() -> itkWatershedImageFilterIF2

        Create a new object of the class itkWatershedImageFilterIF2 and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkWatershedImageFilterIF2.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkWatershedImageFilterIF2.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkWatershedImageFilterIF2.__New_orig__()
        from itk.support import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkWatershedImageFilterIF2 in _itkWatershedImageFilterPython:
_itkWatershedImageFilterPython.itkWatershedImageFilterIF2_swigregister(itkWatershedImageFilterIF2)
itkWatershedImageFilterIF2___New_orig__ = _itkWatershedImageFilterPython.itkWatershedImageFilterIF2___New_orig__
itkWatershedImageFilterIF2_cast = _itkWatershedImageFilterPython.itkWatershedImageFilterIF2_cast


def itkWatershedImageFilterIF3_New():
    return itkWatershedImageFilterIF3.New()

class itkWatershedImageFilterIF3(itk.itkImageToImageFilterAPython.itkImageToImageFilterIF3IUL3):
    r"""


    A low-level image analysis algorithm that automatically produces a
    hierarchy of segmented, labeled images from a scalar-valued image
    input.

    Overview and terminology

    This filter implements a non-streaming version of an image
    segmentation algorithm commonly known as "watershed segmentation".
    Watershed segmentation gets its name from the manner in which the
    algorithm segments regions into catchment basins. If a function $ f $
    is a continuous height function defined over an image domain, then a
    catchment basin is defined as the set of points whose paths of
    steepest descent terminate at the same local minimum of $ f $.

    The choice of height function (input) depends on the application, and
    the basic watershed algorithm operates independently of that choice.
    For intensity-based image data, you might typically use some sort of
    gradient magnitude calculation as input. (see
    itk::GradientMagnitudeImageFilter)

    The watershed algorithm proceeds in several steps. First, an initial
    classification of all points into catchment basin regions is done by
    tracing each point down its path of steepest descent to a local
    minima. Next, neighboring regions and the boundaries between them are
    analyzed according to some saliency measure (such as minimum boundary
    height) to produce a tree of merges among adjacent regions. These
    merges occur at different maximum saliency values. The collective set
    of all possible merges up to a specified saliency "flood level" is
    referred to in this documentation as a "merge tree". Metaphorically,
    the flood level is a value that reflects the amount of precipitation
    that is rained into the catchment basins. As the flood level rises,
    boundaries between adjacent segments erode and those segments merge.
    The minimum value of the flood level is zero and the maximum value is
    the difference between the highest and lowest values in the input
    image.

    Note that once the initial analysis and segmentation is done to
    produce the merge tree, it is trivial to produce a hierarchy of
    labeled images in constant time. The complexity of the algorithm is in
    the computation of the merge tree. Once that tree has been created,
    the initial segmented image can be relabeled to reflect any maximum
    saliency value found in the tree by simply identifying a subset of
    segment merges from the tree. Implementational details This filter is
    a wrapper for several lower level process objects (watershed algorithm
    components in the namespace "watershed"). For a more complete
    picture of the implementation, refer to the documentation of those
    components. The component classes were designed to operate in either a
    data-streaming or a non-data-streaming mode. The pipeline constructed
    in this class' GenerateData() method does not support streaming, but
    is the common use case for the components. Description of the input to
    this filter The input to this filter is a scalar itk::Image of any
    dimensionality. This input image is assumed to represent some sort of
    height function or edge map based on the original image that you want
    to segment (such as would be produced by
    itk::GradientMagnitudeImageFilter). This filter does not do any pre-
    processing on its input other than a thresholding step. The algorithm
    does not explicitly require that the input be of any particular data
    type, but floating point or double precision data is recommended.

    The recommended pre-processing for scalar image input to this
    algorithm is to use one of the itk::AnisotropicDiffusionImageFilter
    subclasses to smooth the original image and then perform some sort of
    edge calculation based on gradients or curvature. Description of the
    output of this filter This filter will produce an itk::Image of
    IdentifierType integer type and of the same dimensionality as the
    input image. The IdentifierType output image is referred to as the
    "labeled image" in this documentation. Each pixel in the image is
    assigned an IdentifierType integer label that groups it within a
    connected region. Some notes on filter parameters Two parameters
    control the output of this filter, Threshold and Level. The units of
    both parameters are percentage points of the maximum height value in
    the input.

    Threshold is used to set the absolute minimum height value used during
    processing. Raising this threshold percentage effectively decreases
    the number of local minima in the input, resulting in an initial
    segmentation with fewer regions. The assumption is that the shallow
    regions that thresholding removes are of of less interest.

    The Level parameter controls the depth of metaphorical flooding of the
    image. That is, it sets the maximum saliency value of interest in the
    result. Raising and lowering the Level influences the number of
    segments in the basic segmentation that are merged to produce the
    final output. A level of 1.0 is analogous to flooding the image up to
    a depth that is 100 percent of the maximum value in the image. A level
    of 0.0 produces the basic segmentation, which will typically be very
    oversegmented. Level values of interest are typically low (i.e. less
    than about 0.40 or 40% ), since higher values quickly start to
    undersegment the image.

    The Level parameter can be used to create a hierarchy of output images
    in constant time once an initial segmentation is done. A typical
    scenario might go like this: For the initial execution of the filter,
    set the Level to the maximum saliency value that you anticipate might
    be of interest. Once the initial Update() of this process object has
    finished, the Level can be manipulated anywhere below the initial
    setting without triggering a full update of the segmentation mini-
    pipeline. All that is now be required to produce the new output is a
    simple relabeling of the output image.

    Threshold and Level parameters are controlled through the class'
    Get/SetThreshold() and Get/SetLevel() methods.
    example{Segmentation/Watersheds/SegmentWithWatershedImageFilter,Wa
    tershed Image Filter} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF3___New_orig__)
    Clone = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF3_Clone)
    GenerateData = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF3_GenerateData)
    SetInput = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF3_SetInput)
    SetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF3_SetThreshold)
    GetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF3_GetThreshold)
    SetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF3_SetLevel)
    GetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF3_GetLevel)
    GetBasicSegmentation = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF3_GetBasicSegmentation)
    GetSegmentTree = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF3_GetSegmentTree)
    InputEqualityComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIF3_InputEqualityComparableCheck
    
    InputAdditiveOperatorsCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIF3_InputAdditiveOperatorsCheck
    
    DoubleInputMultiplyOperatorCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIF3_DoubleInputMultiplyOperatorCheck
    
    InputLessThanComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIF3_InputLessThanComparableCheck
    
    __swig_destroy__ = _itkWatershedImageFilterPython.delete_itkWatershedImageFilterIF3
    cast = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF3_cast)

    def New(*args, **kargs):
        """New() -> itkWatershedImageFilterIF3

        Create a new object of the class itkWatershedImageFilterIF3 and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkWatershedImageFilterIF3.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkWatershedImageFilterIF3.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkWatershedImageFilterIF3.__New_orig__()
        from itk.support import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkWatershedImageFilterIF3 in _itkWatershedImageFilterPython:
_itkWatershedImageFilterPython.itkWatershedImageFilterIF3_swigregister(itkWatershedImageFilterIF3)
itkWatershedImageFilterIF3___New_orig__ = _itkWatershedImageFilterPython.itkWatershedImageFilterIF3___New_orig__
itkWatershedImageFilterIF3_cast = _itkWatershedImageFilterPython.itkWatershedImageFilterIF3_cast


def itkWatershedImageFilterIF4_New():
    return itkWatershedImageFilterIF4.New()

class itkWatershedImageFilterIF4(itk.itkImageToImageFilterAPython.itkImageToImageFilterIF4IUL4):
    r"""


    A low-level image analysis algorithm that automatically produces a
    hierarchy of segmented, labeled images from a scalar-valued image
    input.

    Overview and terminology

    This filter implements a non-streaming version of an image
    segmentation algorithm commonly known as "watershed segmentation".
    Watershed segmentation gets its name from the manner in which the
    algorithm segments regions into catchment basins. If a function $ f $
    is a continuous height function defined over an image domain, then a
    catchment basin is defined as the set of points whose paths of
    steepest descent terminate at the same local minimum of $ f $.

    The choice of height function (input) depends on the application, and
    the basic watershed algorithm operates independently of that choice.
    For intensity-based image data, you might typically use some sort of
    gradient magnitude calculation as input. (see
    itk::GradientMagnitudeImageFilter)

    The watershed algorithm proceeds in several steps. First, an initial
    classification of all points into catchment basin regions is done by
    tracing each point down its path of steepest descent to a local
    minima. Next, neighboring regions and the boundaries between them are
    analyzed according to some saliency measure (such as minimum boundary
    height) to produce a tree of merges among adjacent regions. These
    merges occur at different maximum saliency values. The collective set
    of all possible merges up to a specified saliency "flood level" is
    referred to in this documentation as a "merge tree". Metaphorically,
    the flood level is a value that reflects the amount of precipitation
    that is rained into the catchment basins. As the flood level rises,
    boundaries between adjacent segments erode and those segments merge.
    The minimum value of the flood level is zero and the maximum value is
    the difference between the highest and lowest values in the input
    image.

    Note that once the initial analysis and segmentation is done to
    produce the merge tree, it is trivial to produce a hierarchy of
    labeled images in constant time. The complexity of the algorithm is in
    the computation of the merge tree. Once that tree has been created,
    the initial segmented image can be relabeled to reflect any maximum
    saliency value found in the tree by simply identifying a subset of
    segment merges from the tree. Implementational details This filter is
    a wrapper for several lower level process objects (watershed algorithm
    components in the namespace "watershed"). For a more complete
    picture of the implementation, refer to the documentation of those
    components. The component classes were designed to operate in either a
    data-streaming or a non-data-streaming mode. The pipeline constructed
    in this class' GenerateData() method does not support streaming, but
    is the common use case for the components. Description of the input to
    this filter The input to this filter is a scalar itk::Image of any
    dimensionality. This input image is assumed to represent some sort of
    height function or edge map based on the original image that you want
    to segment (such as would be produced by
    itk::GradientMagnitudeImageFilter). This filter does not do any pre-
    processing on its input other than a thresholding step. The algorithm
    does not explicitly require that the input be of any particular data
    type, but floating point or double precision data is recommended.

    The recommended pre-processing for scalar image input to this
    algorithm is to use one of the itk::AnisotropicDiffusionImageFilter
    subclasses to smooth the original image and then perform some sort of
    edge calculation based on gradients or curvature. Description of the
    output of this filter This filter will produce an itk::Image of
    IdentifierType integer type and of the same dimensionality as the
    input image. The IdentifierType output image is referred to as the
    "labeled image" in this documentation. Each pixel in the image is
    assigned an IdentifierType integer label that groups it within a
    connected region. Some notes on filter parameters Two parameters
    control the output of this filter, Threshold and Level. The units of
    both parameters are percentage points of the maximum height value in
    the input.

    Threshold is used to set the absolute minimum height value used during
    processing. Raising this threshold percentage effectively decreases
    the number of local minima in the input, resulting in an initial
    segmentation with fewer regions. The assumption is that the shallow
    regions that thresholding removes are of of less interest.

    The Level parameter controls the depth of metaphorical flooding of the
    image. That is, it sets the maximum saliency value of interest in the
    result. Raising and lowering the Level influences the number of
    segments in the basic segmentation that are merged to produce the
    final output. A level of 1.0 is analogous to flooding the image up to
    a depth that is 100 percent of the maximum value in the image. A level
    of 0.0 produces the basic segmentation, which will typically be very
    oversegmented. Level values of interest are typically low (i.e. less
    than about 0.40 or 40% ), since higher values quickly start to
    undersegment the image.

    The Level parameter can be used to create a hierarchy of output images
    in constant time once an initial segmentation is done. A typical
    scenario might go like this: For the initial execution of the filter,
    set the Level to the maximum saliency value that you anticipate might
    be of interest. Once the initial Update() of this process object has
    finished, the Level can be manipulated anywhere below the initial
    setting without triggering a full update of the segmentation mini-
    pipeline. All that is now be required to produce the new output is a
    simple relabeling of the output image.

    Threshold and Level parameters are controlled through the class'
    Get/SetThreshold() and Get/SetLevel() methods.
    example{Segmentation/Watersheds/SegmentWithWatershedImageFilter,Wa
    tershed Image Filter} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF4___New_orig__)
    Clone = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF4_Clone)
    GenerateData = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF4_GenerateData)
    SetInput = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF4_SetInput)
    SetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF4_SetThreshold)
    GetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF4_GetThreshold)
    SetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF4_SetLevel)
    GetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF4_GetLevel)
    GetBasicSegmentation = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF4_GetBasicSegmentation)
    GetSegmentTree = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF4_GetSegmentTree)
    InputEqualityComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIF4_InputEqualityComparableCheck
    
    InputAdditiveOperatorsCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIF4_InputAdditiveOperatorsCheck
    
    DoubleInputMultiplyOperatorCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIF4_DoubleInputMultiplyOperatorCheck
    
    InputLessThanComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIF4_InputLessThanComparableCheck
    
    __swig_destroy__ = _itkWatershedImageFilterPython.delete_itkWatershedImageFilterIF4
    cast = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIF4_cast)

    def New(*args, **kargs):
        """New() -> itkWatershedImageFilterIF4

        Create a new object of the class itkWatershedImageFilterIF4 and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkWatershedImageFilterIF4.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkWatershedImageFilterIF4.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkWatershedImageFilterIF4.__New_orig__()
        from itk.support import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkWatershedImageFilterIF4 in _itkWatershedImageFilterPython:
_itkWatershedImageFilterPython.itkWatershedImageFilterIF4_swigregister(itkWatershedImageFilterIF4)
itkWatershedImageFilterIF4___New_orig__ = _itkWatershedImageFilterPython.itkWatershedImageFilterIF4___New_orig__
itkWatershedImageFilterIF4_cast = _itkWatershedImageFilterPython.itkWatershedImageFilterIF4_cast


def itkWatershedImageFilterISS2_New():
    return itkWatershedImageFilterISS2.New()

class itkWatershedImageFilterISS2(itk.itkImageToImageFilterAPython.itkImageToImageFilterISS2IUL2):
    r"""


    A low-level image analysis algorithm that automatically produces a
    hierarchy of segmented, labeled images from a scalar-valued image
    input.

    Overview and terminology

    This filter implements a non-streaming version of an image
    segmentation algorithm commonly known as "watershed segmentation".
    Watershed segmentation gets its name from the manner in which the
    algorithm segments regions into catchment basins. If a function $ f $
    is a continuous height function defined over an image domain, then a
    catchment basin is defined as the set of points whose paths of
    steepest descent terminate at the same local minimum of $ f $.

    The choice of height function (input) depends on the application, and
    the basic watershed algorithm operates independently of that choice.
    For intensity-based image data, you might typically use some sort of
    gradient magnitude calculation as input. (see
    itk::GradientMagnitudeImageFilter)

    The watershed algorithm proceeds in several steps. First, an initial
    classification of all points into catchment basin regions is done by
    tracing each point down its path of steepest descent to a local
    minima. Next, neighboring regions and the boundaries between them are
    analyzed according to some saliency measure (such as minimum boundary
    height) to produce a tree of merges among adjacent regions. These
    merges occur at different maximum saliency values. The collective set
    of all possible merges up to a specified saliency "flood level" is
    referred to in this documentation as a "merge tree". Metaphorically,
    the flood level is a value that reflects the amount of precipitation
    that is rained into the catchment basins. As the flood level rises,
    boundaries between adjacent segments erode and those segments merge.
    The minimum value of the flood level is zero and the maximum value is
    the difference between the highest and lowest values in the input
    image.

    Note that once the initial analysis and segmentation is done to
    produce the merge tree, it is trivial to produce a hierarchy of
    labeled images in constant time. The complexity of the algorithm is in
    the computation of the merge tree. Once that tree has been created,
    the initial segmented image can be relabeled to reflect any maximum
    saliency value found in the tree by simply identifying a subset of
    segment merges from the tree. Implementational details This filter is
    a wrapper for several lower level process objects (watershed algorithm
    components in the namespace "watershed"). For a more complete
    picture of the implementation, refer to the documentation of those
    components. The component classes were designed to operate in either a
    data-streaming or a non-data-streaming mode. The pipeline constructed
    in this class' GenerateData() method does not support streaming, but
    is the common use case for the components. Description of the input to
    this filter The input to this filter is a scalar itk::Image of any
    dimensionality. This input image is assumed to represent some sort of
    height function or edge map based on the original image that you want
    to segment (such as would be produced by
    itk::GradientMagnitudeImageFilter). This filter does not do any pre-
    processing on its input other than a thresholding step. The algorithm
    does not explicitly require that the input be of any particular data
    type, but floating point or double precision data is recommended.

    The recommended pre-processing for scalar image input to this
    algorithm is to use one of the itk::AnisotropicDiffusionImageFilter
    subclasses to smooth the original image and then perform some sort of
    edge calculation based on gradients or curvature. Description of the
    output of this filter This filter will produce an itk::Image of
    IdentifierType integer type and of the same dimensionality as the
    input image. The IdentifierType output image is referred to as the
    "labeled image" in this documentation. Each pixel in the image is
    assigned an IdentifierType integer label that groups it within a
    connected region. Some notes on filter parameters Two parameters
    control the output of this filter, Threshold and Level. The units of
    both parameters are percentage points of the maximum height value in
    the input.

    Threshold is used to set the absolute minimum height value used during
    processing. Raising this threshold percentage effectively decreases
    the number of local minima in the input, resulting in an initial
    segmentation with fewer regions. The assumption is that the shallow
    regions that thresholding removes are of of less interest.

    The Level parameter controls the depth of metaphorical flooding of the
    image. That is, it sets the maximum saliency value of interest in the
    result. Raising and lowering the Level influences the number of
    segments in the basic segmentation that are merged to produce the
    final output. A level of 1.0 is analogous to flooding the image up to
    a depth that is 100 percent of the maximum value in the image. A level
    of 0.0 produces the basic segmentation, which will typically be very
    oversegmented. Level values of interest are typically low (i.e. less
    than about 0.40 or 40% ), since higher values quickly start to
    undersegment the image.

    The Level parameter can be used to create a hierarchy of output images
    in constant time once an initial segmentation is done. A typical
    scenario might go like this: For the initial execution of the filter,
    set the Level to the maximum saliency value that you anticipate might
    be of interest. Once the initial Update() of this process object has
    finished, the Level can be manipulated anywhere below the initial
    setting without triggering a full update of the segmentation mini-
    pipeline. All that is now be required to produce the new output is a
    simple relabeling of the output image.

    Threshold and Level parameters are controlled through the class'
    Get/SetThreshold() and Get/SetLevel() methods.
    example{Segmentation/Watersheds/SegmentWithWatershedImageFilter,Wa
    tershed Image Filter} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS2___New_orig__)
    Clone = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS2_Clone)
    GenerateData = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS2_GenerateData)
    SetInput = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS2_SetInput)
    SetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS2_SetThreshold)
    GetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS2_GetThreshold)
    SetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS2_SetLevel)
    GetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS2_GetLevel)
    GetBasicSegmentation = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS2_GetBasicSegmentation)
    GetSegmentTree = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS2_GetSegmentTree)
    InputEqualityComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterISS2_InputEqualityComparableCheck
    
    InputAdditiveOperatorsCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterISS2_InputAdditiveOperatorsCheck
    
    DoubleInputMultiplyOperatorCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterISS2_DoubleInputMultiplyOperatorCheck
    
    InputLessThanComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterISS2_InputLessThanComparableCheck
    
    __swig_destroy__ = _itkWatershedImageFilterPython.delete_itkWatershedImageFilterISS2
    cast = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS2_cast)

    def New(*args, **kargs):
        """New() -> itkWatershedImageFilterISS2

        Create a new object of the class itkWatershedImageFilterISS2 and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkWatershedImageFilterISS2.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkWatershedImageFilterISS2.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkWatershedImageFilterISS2.__New_orig__()
        from itk.support import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkWatershedImageFilterISS2 in _itkWatershedImageFilterPython:
_itkWatershedImageFilterPython.itkWatershedImageFilterISS2_swigregister(itkWatershedImageFilterISS2)
itkWatershedImageFilterISS2___New_orig__ = _itkWatershedImageFilterPython.itkWatershedImageFilterISS2___New_orig__
itkWatershedImageFilterISS2_cast = _itkWatershedImageFilterPython.itkWatershedImageFilterISS2_cast


def itkWatershedImageFilterISS3_New():
    return itkWatershedImageFilterISS3.New()

class itkWatershedImageFilterISS3(itk.itkImageToImageFilterAPython.itkImageToImageFilterISS3IUL3):
    r"""


    A low-level image analysis algorithm that automatically produces a
    hierarchy of segmented, labeled images from a scalar-valued image
    input.

    Overview and terminology

    This filter implements a non-streaming version of an image
    segmentation algorithm commonly known as "watershed segmentation".
    Watershed segmentation gets its name from the manner in which the
    algorithm segments regions into catchment basins. If a function $ f $
    is a continuous height function defined over an image domain, then a
    catchment basin is defined as the set of points whose paths of
    steepest descent terminate at the same local minimum of $ f $.

    The choice of height function (input) depends on the application, and
    the basic watershed algorithm operates independently of that choice.
    For intensity-based image data, you might typically use some sort of
    gradient magnitude calculation as input. (see
    itk::GradientMagnitudeImageFilter)

    The watershed algorithm proceeds in several steps. First, an initial
    classification of all points into catchment basin regions is done by
    tracing each point down its path of steepest descent to a local
    minima. Next, neighboring regions and the boundaries between them are
    analyzed according to some saliency measure (such as minimum boundary
    height) to produce a tree of merges among adjacent regions. These
    merges occur at different maximum saliency values. The collective set
    of all possible merges up to a specified saliency "flood level" is
    referred to in this documentation as a "merge tree". Metaphorically,
    the flood level is a value that reflects the amount of precipitation
    that is rained into the catchment basins. As the flood level rises,
    boundaries between adjacent segments erode and those segments merge.
    The minimum value of the flood level is zero and the maximum value is
    the difference between the highest and lowest values in the input
    image.

    Note that once the initial analysis and segmentation is done to
    produce the merge tree, it is trivial to produce a hierarchy of
    labeled images in constant time. The complexity of the algorithm is in
    the computation of the merge tree. Once that tree has been created,
    the initial segmented image can be relabeled to reflect any maximum
    saliency value found in the tree by simply identifying a subset of
    segment merges from the tree. Implementational details This filter is
    a wrapper for several lower level process objects (watershed algorithm
    components in the namespace "watershed"). For a more complete
    picture of the implementation, refer to the documentation of those
    components. The component classes were designed to operate in either a
    data-streaming or a non-data-streaming mode. The pipeline constructed
    in this class' GenerateData() method does not support streaming, but
    is the common use case for the components. Description of the input to
    this filter The input to this filter is a scalar itk::Image of any
    dimensionality. This input image is assumed to represent some sort of
    height function or edge map based on the original image that you want
    to segment (such as would be produced by
    itk::GradientMagnitudeImageFilter). This filter does not do any pre-
    processing on its input other than a thresholding step. The algorithm
    does not explicitly require that the input be of any particular data
    type, but floating point or double precision data is recommended.

    The recommended pre-processing for scalar image input to this
    algorithm is to use one of the itk::AnisotropicDiffusionImageFilter
    subclasses to smooth the original image and then perform some sort of
    edge calculation based on gradients or curvature. Description of the
    output of this filter This filter will produce an itk::Image of
    IdentifierType integer type and of the same dimensionality as the
    input image. The IdentifierType output image is referred to as the
    "labeled image" in this documentation. Each pixel in the image is
    assigned an IdentifierType integer label that groups it within a
    connected region. Some notes on filter parameters Two parameters
    control the output of this filter, Threshold and Level. The units of
    both parameters are percentage points of the maximum height value in
    the input.

    Threshold is used to set the absolute minimum height value used during
    processing. Raising this threshold percentage effectively decreases
    the number of local minima in the input, resulting in an initial
    segmentation with fewer regions. The assumption is that the shallow
    regions that thresholding removes are of of less interest.

    The Level parameter controls the depth of metaphorical flooding of the
    image. That is, it sets the maximum saliency value of interest in the
    result. Raising and lowering the Level influences the number of
    segments in the basic segmentation that are merged to produce the
    final output. A level of 1.0 is analogous to flooding the image up to
    a depth that is 100 percent of the maximum value in the image. A level
    of 0.0 produces the basic segmentation, which will typically be very
    oversegmented. Level values of interest are typically low (i.e. less
    than about 0.40 or 40% ), since higher values quickly start to
    undersegment the image.

    The Level parameter can be used to create a hierarchy of output images
    in constant time once an initial segmentation is done. A typical
    scenario might go like this: For the initial execution of the filter,
    set the Level to the maximum saliency value that you anticipate might
    be of interest. Once the initial Update() of this process object has
    finished, the Level can be manipulated anywhere below the initial
    setting without triggering a full update of the segmentation mini-
    pipeline. All that is now be required to produce the new output is a
    simple relabeling of the output image.

    Threshold and Level parameters are controlled through the class'
    Get/SetThreshold() and Get/SetLevel() methods.
    example{Segmentation/Watersheds/SegmentWithWatershedImageFilter,Wa
    tershed Image Filter} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS3___New_orig__)
    Clone = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS3_Clone)
    GenerateData = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS3_GenerateData)
    SetInput = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS3_SetInput)
    SetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS3_SetThreshold)
    GetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS3_GetThreshold)
    SetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS3_SetLevel)
    GetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS3_GetLevel)
    GetBasicSegmentation = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS3_GetBasicSegmentation)
    GetSegmentTree = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS3_GetSegmentTree)
    InputEqualityComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterISS3_InputEqualityComparableCheck
    
    InputAdditiveOperatorsCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterISS3_InputAdditiveOperatorsCheck
    
    DoubleInputMultiplyOperatorCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterISS3_DoubleInputMultiplyOperatorCheck
    
    InputLessThanComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterISS3_InputLessThanComparableCheck
    
    __swig_destroy__ = _itkWatershedImageFilterPython.delete_itkWatershedImageFilterISS3
    cast = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS3_cast)

    def New(*args, **kargs):
        """New() -> itkWatershedImageFilterISS3

        Create a new object of the class itkWatershedImageFilterISS3 and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkWatershedImageFilterISS3.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkWatershedImageFilterISS3.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkWatershedImageFilterISS3.__New_orig__()
        from itk.support import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkWatershedImageFilterISS3 in _itkWatershedImageFilterPython:
_itkWatershedImageFilterPython.itkWatershedImageFilterISS3_swigregister(itkWatershedImageFilterISS3)
itkWatershedImageFilterISS3___New_orig__ = _itkWatershedImageFilterPython.itkWatershedImageFilterISS3___New_orig__
itkWatershedImageFilterISS3_cast = _itkWatershedImageFilterPython.itkWatershedImageFilterISS3_cast


def itkWatershedImageFilterISS4_New():
    return itkWatershedImageFilterISS4.New()

class itkWatershedImageFilterISS4(itk.itkImageToImageFilterAPython.itkImageToImageFilterISS4IUL4):
    r"""


    A low-level image analysis algorithm that automatically produces a
    hierarchy of segmented, labeled images from a scalar-valued image
    input.

    Overview and terminology

    This filter implements a non-streaming version of an image
    segmentation algorithm commonly known as "watershed segmentation".
    Watershed segmentation gets its name from the manner in which the
    algorithm segments regions into catchment basins. If a function $ f $
    is a continuous height function defined over an image domain, then a
    catchment basin is defined as the set of points whose paths of
    steepest descent terminate at the same local minimum of $ f $.

    The choice of height function (input) depends on the application, and
    the basic watershed algorithm operates independently of that choice.
    For intensity-based image data, you might typically use some sort of
    gradient magnitude calculation as input. (see
    itk::GradientMagnitudeImageFilter)

    The watershed algorithm proceeds in several steps. First, an initial
    classification of all points into catchment basin regions is done by
    tracing each point down its path of steepest descent to a local
    minima. Next, neighboring regions and the boundaries between them are
    analyzed according to some saliency measure (such as minimum boundary
    height) to produce a tree of merges among adjacent regions. These
    merges occur at different maximum saliency values. The collective set
    of all possible merges up to a specified saliency "flood level" is
    referred to in this documentation as a "merge tree". Metaphorically,
    the flood level is a value that reflects the amount of precipitation
    that is rained into the catchment basins. As the flood level rises,
    boundaries between adjacent segments erode and those segments merge.
    The minimum value of the flood level is zero and the maximum value is
    the difference between the highest and lowest values in the input
    image.

    Note that once the initial analysis and segmentation is done to
    produce the merge tree, it is trivial to produce a hierarchy of
    labeled images in constant time. The complexity of the algorithm is in
    the computation of the merge tree. Once that tree has been created,
    the initial segmented image can be relabeled to reflect any maximum
    saliency value found in the tree by simply identifying a subset of
    segment merges from the tree. Implementational details This filter is
    a wrapper for several lower level process objects (watershed algorithm
    components in the namespace "watershed"). For a more complete
    picture of the implementation, refer to the documentation of those
    components. The component classes were designed to operate in either a
    data-streaming or a non-data-streaming mode. The pipeline constructed
    in this class' GenerateData() method does not support streaming, but
    is the common use case for the components. Description of the input to
    this filter The input to this filter is a scalar itk::Image of any
    dimensionality. This input image is assumed to represent some sort of
    height function or edge map based on the original image that you want
    to segment (such as would be produced by
    itk::GradientMagnitudeImageFilter). This filter does not do any pre-
    processing on its input other than a thresholding step. The algorithm
    does not explicitly require that the input be of any particular data
    type, but floating point or double precision data is recommended.

    The recommended pre-processing for scalar image input to this
    algorithm is to use one of the itk::AnisotropicDiffusionImageFilter
    subclasses to smooth the original image and then perform some sort of
    edge calculation based on gradients or curvature. Description of the
    output of this filter This filter will produce an itk::Image of
    IdentifierType integer type and of the same dimensionality as the
    input image. The IdentifierType output image is referred to as the
    "labeled image" in this documentation. Each pixel in the image is
    assigned an IdentifierType integer label that groups it within a
    connected region. Some notes on filter parameters Two parameters
    control the output of this filter, Threshold and Level. The units of
    both parameters are percentage points of the maximum height value in
    the input.

    Threshold is used to set the absolute minimum height value used during
    processing. Raising this threshold percentage effectively decreases
    the number of local minima in the input, resulting in an initial
    segmentation with fewer regions. The assumption is that the shallow
    regions that thresholding removes are of of less interest.

    The Level parameter controls the depth of metaphorical flooding of the
    image. That is, it sets the maximum saliency value of interest in the
    result. Raising and lowering the Level influences the number of
    segments in the basic segmentation that are merged to produce the
    final output. A level of 1.0 is analogous to flooding the image up to
    a depth that is 100 percent of the maximum value in the image. A level
    of 0.0 produces the basic segmentation, which will typically be very
    oversegmented. Level values of interest are typically low (i.e. less
    than about 0.40 or 40% ), since higher values quickly start to
    undersegment the image.

    The Level parameter can be used to create a hierarchy of output images
    in constant time once an initial segmentation is done. A typical
    scenario might go like this: For the initial execution of the filter,
    set the Level to the maximum saliency value that you anticipate might
    be of interest. Once the initial Update() of this process object has
    finished, the Level can be manipulated anywhere below the initial
    setting without triggering a full update of the segmentation mini-
    pipeline. All that is now be required to produce the new output is a
    simple relabeling of the output image.

    Threshold and Level parameters are controlled through the class'
    Get/SetThreshold() and Get/SetLevel() methods.
    example{Segmentation/Watersheds/SegmentWithWatershedImageFilter,Wa
    tershed Image Filter} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS4___New_orig__)
    Clone = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS4_Clone)
    GenerateData = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS4_GenerateData)
    SetInput = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS4_SetInput)
    SetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS4_SetThreshold)
    GetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS4_GetThreshold)
    SetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS4_SetLevel)
    GetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS4_GetLevel)
    GetBasicSegmentation = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS4_GetBasicSegmentation)
    GetSegmentTree = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS4_GetSegmentTree)
    InputEqualityComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterISS4_InputEqualityComparableCheck
    
    InputAdditiveOperatorsCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterISS4_InputAdditiveOperatorsCheck
    
    DoubleInputMultiplyOperatorCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterISS4_DoubleInputMultiplyOperatorCheck
    
    InputLessThanComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterISS4_InputLessThanComparableCheck
    
    __swig_destroy__ = _itkWatershedImageFilterPython.delete_itkWatershedImageFilterISS4
    cast = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterISS4_cast)

    def New(*args, **kargs):
        """New() -> itkWatershedImageFilterISS4

        Create a new object of the class itkWatershedImageFilterISS4 and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkWatershedImageFilterISS4.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkWatershedImageFilterISS4.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkWatershedImageFilterISS4.__New_orig__()
        from itk.support import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkWatershedImageFilterISS4 in _itkWatershedImageFilterPython:
_itkWatershedImageFilterPython.itkWatershedImageFilterISS4_swigregister(itkWatershedImageFilterISS4)
itkWatershedImageFilterISS4___New_orig__ = _itkWatershedImageFilterPython.itkWatershedImageFilterISS4___New_orig__
itkWatershedImageFilterISS4_cast = _itkWatershedImageFilterPython.itkWatershedImageFilterISS4_cast


def itkWatershedImageFilterIUC2_New():
    return itkWatershedImageFilterIUC2.New()

class itkWatershedImageFilterIUC2(itk.itkImageToImageFilterAPython.itkImageToImageFilterIUC2IUL2):
    r"""


    A low-level image analysis algorithm that automatically produces a
    hierarchy of segmented, labeled images from a scalar-valued image
    input.

    Overview and terminology

    This filter implements a non-streaming version of an image
    segmentation algorithm commonly known as "watershed segmentation".
    Watershed segmentation gets its name from the manner in which the
    algorithm segments regions into catchment basins. If a function $ f $
    is a continuous height function defined over an image domain, then a
    catchment basin is defined as the set of points whose paths of
    steepest descent terminate at the same local minimum of $ f $.

    The choice of height function (input) depends on the application, and
    the basic watershed algorithm operates independently of that choice.
    For intensity-based image data, you might typically use some sort of
    gradient magnitude calculation as input. (see
    itk::GradientMagnitudeImageFilter)

    The watershed algorithm proceeds in several steps. First, an initial
    classification of all points into catchment basin regions is done by
    tracing each point down its path of steepest descent to a local
    minima. Next, neighboring regions and the boundaries between them are
    analyzed according to some saliency measure (such as minimum boundary
    height) to produce a tree of merges among adjacent regions. These
    merges occur at different maximum saliency values. The collective set
    of all possible merges up to a specified saliency "flood level" is
    referred to in this documentation as a "merge tree". Metaphorically,
    the flood level is a value that reflects the amount of precipitation
    that is rained into the catchment basins. As the flood level rises,
    boundaries between adjacent segments erode and those segments merge.
    The minimum value of the flood level is zero and the maximum value is
    the difference between the highest and lowest values in the input
    image.

    Note that once the initial analysis and segmentation is done to
    produce the merge tree, it is trivial to produce a hierarchy of
    labeled images in constant time. The complexity of the algorithm is in
    the computation of the merge tree. Once that tree has been created,
    the initial segmented image can be relabeled to reflect any maximum
    saliency value found in the tree by simply identifying a subset of
    segment merges from the tree. Implementational details This filter is
    a wrapper for several lower level process objects (watershed algorithm
    components in the namespace "watershed"). For a more complete
    picture of the implementation, refer to the documentation of those
    components. The component classes were designed to operate in either a
    data-streaming or a non-data-streaming mode. The pipeline constructed
    in this class' GenerateData() method does not support streaming, but
    is the common use case for the components. Description of the input to
    this filter The input to this filter is a scalar itk::Image of any
    dimensionality. This input image is assumed to represent some sort of
    height function or edge map based on the original image that you want
    to segment (such as would be produced by
    itk::GradientMagnitudeImageFilter). This filter does not do any pre-
    processing on its input other than a thresholding step. The algorithm
    does not explicitly require that the input be of any particular data
    type, but floating point or double precision data is recommended.

    The recommended pre-processing for scalar image input to this
    algorithm is to use one of the itk::AnisotropicDiffusionImageFilter
    subclasses to smooth the original image and then perform some sort of
    edge calculation based on gradients or curvature. Description of the
    output of this filter This filter will produce an itk::Image of
    IdentifierType integer type and of the same dimensionality as the
    input image. The IdentifierType output image is referred to as the
    "labeled image" in this documentation. Each pixel in the image is
    assigned an IdentifierType integer label that groups it within a
    connected region. Some notes on filter parameters Two parameters
    control the output of this filter, Threshold and Level. The units of
    both parameters are percentage points of the maximum height value in
    the input.

    Threshold is used to set the absolute minimum height value used during
    processing. Raising this threshold percentage effectively decreases
    the number of local minima in the input, resulting in an initial
    segmentation with fewer regions. The assumption is that the shallow
    regions that thresholding removes are of of less interest.

    The Level parameter controls the depth of metaphorical flooding of the
    image. That is, it sets the maximum saliency value of interest in the
    result. Raising and lowering the Level influences the number of
    segments in the basic segmentation that are merged to produce the
    final output. A level of 1.0 is analogous to flooding the image up to
    a depth that is 100 percent of the maximum value in the image. A level
    of 0.0 produces the basic segmentation, which will typically be very
    oversegmented. Level values of interest are typically low (i.e. less
    than about 0.40 or 40% ), since higher values quickly start to
    undersegment the image.

    The Level parameter can be used to create a hierarchy of output images
    in constant time once an initial segmentation is done. A typical
    scenario might go like this: For the initial execution of the filter,
    set the Level to the maximum saliency value that you anticipate might
    be of interest. Once the initial Update() of this process object has
    finished, the Level can be manipulated anywhere below the initial
    setting without triggering a full update of the segmentation mini-
    pipeline. All that is now be required to produce the new output is a
    simple relabeling of the output image.

    Threshold and Level parameters are controlled through the class'
    Get/SetThreshold() and Get/SetLevel() methods.
    example{Segmentation/Watersheds/SegmentWithWatershedImageFilter,Wa
    tershed Image Filter} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC2___New_orig__)
    Clone = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC2_Clone)
    GenerateData = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC2_GenerateData)
    SetInput = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC2_SetInput)
    SetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC2_SetThreshold)
    GetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC2_GetThreshold)
    SetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC2_SetLevel)
    GetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC2_GetLevel)
    GetBasicSegmentation = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC2_GetBasicSegmentation)
    GetSegmentTree = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC2_GetSegmentTree)
    InputEqualityComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIUC2_InputEqualityComparableCheck
    
    InputAdditiveOperatorsCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIUC2_InputAdditiveOperatorsCheck
    
    DoubleInputMultiplyOperatorCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIUC2_DoubleInputMultiplyOperatorCheck
    
    InputLessThanComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIUC2_InputLessThanComparableCheck
    
    __swig_destroy__ = _itkWatershedImageFilterPython.delete_itkWatershedImageFilterIUC2
    cast = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC2_cast)

    def New(*args, **kargs):
        """New() -> itkWatershedImageFilterIUC2

        Create a new object of the class itkWatershedImageFilterIUC2 and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkWatershedImageFilterIUC2.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkWatershedImageFilterIUC2.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkWatershedImageFilterIUC2.__New_orig__()
        from itk.support import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkWatershedImageFilterIUC2 in _itkWatershedImageFilterPython:
_itkWatershedImageFilterPython.itkWatershedImageFilterIUC2_swigregister(itkWatershedImageFilterIUC2)
itkWatershedImageFilterIUC2___New_orig__ = _itkWatershedImageFilterPython.itkWatershedImageFilterIUC2___New_orig__
itkWatershedImageFilterIUC2_cast = _itkWatershedImageFilterPython.itkWatershedImageFilterIUC2_cast


def itkWatershedImageFilterIUC3_New():
    return itkWatershedImageFilterIUC3.New()

class itkWatershedImageFilterIUC3(itk.itkImageToImageFilterAPython.itkImageToImageFilterIUC3IUL3):
    r"""


    A low-level image analysis algorithm that automatically produces a
    hierarchy of segmented, labeled images from a scalar-valued image
    input.

    Overview and terminology

    This filter implements a non-streaming version of an image
    segmentation algorithm commonly known as "watershed segmentation".
    Watershed segmentation gets its name from the manner in which the
    algorithm segments regions into catchment basins. If a function $ f $
    is a continuous height function defined over an image domain, then a
    catchment basin is defined as the set of points whose paths of
    steepest descent terminate at the same local minimum of $ f $.

    The choice of height function (input) depends on the application, and
    the basic watershed algorithm operates independently of that choice.
    For intensity-based image data, you might typically use some sort of
    gradient magnitude calculation as input. (see
    itk::GradientMagnitudeImageFilter)

    The watershed algorithm proceeds in several steps. First, an initial
    classification of all points into catchment basin regions is done by
    tracing each point down its path of steepest descent to a local
    minima. Next, neighboring regions and the boundaries between them are
    analyzed according to some saliency measure (such as minimum boundary
    height) to produce a tree of merges among adjacent regions. These
    merges occur at different maximum saliency values. The collective set
    of all possible merges up to a specified saliency "flood level" is
    referred to in this documentation as a "merge tree". Metaphorically,
    the flood level is a value that reflects the amount of precipitation
    that is rained into the catchment basins. As the flood level rises,
    boundaries between adjacent segments erode and those segments merge.
    The minimum value of the flood level is zero and the maximum value is
    the difference between the highest and lowest values in the input
    image.

    Note that once the initial analysis and segmentation is done to
    produce the merge tree, it is trivial to produce a hierarchy of
    labeled images in constant time. The complexity of the algorithm is in
    the computation of the merge tree. Once that tree has been created,
    the initial segmented image can be relabeled to reflect any maximum
    saliency value found in the tree by simply identifying a subset of
    segment merges from the tree. Implementational details This filter is
    a wrapper for several lower level process objects (watershed algorithm
    components in the namespace "watershed"). For a more complete
    picture of the implementation, refer to the documentation of those
    components. The component classes were designed to operate in either a
    data-streaming or a non-data-streaming mode. The pipeline constructed
    in this class' GenerateData() method does not support streaming, but
    is the common use case for the components. Description of the input to
    this filter The input to this filter is a scalar itk::Image of any
    dimensionality. This input image is assumed to represent some sort of
    height function or edge map based on the original image that you want
    to segment (such as would be produced by
    itk::GradientMagnitudeImageFilter). This filter does not do any pre-
    processing on its input other than a thresholding step. The algorithm
    does not explicitly require that the input be of any particular data
    type, but floating point or double precision data is recommended.

    The recommended pre-processing for scalar image input to this
    algorithm is to use one of the itk::AnisotropicDiffusionImageFilter
    subclasses to smooth the original image and then perform some sort of
    edge calculation based on gradients or curvature. Description of the
    output of this filter This filter will produce an itk::Image of
    IdentifierType integer type and of the same dimensionality as the
    input image. The IdentifierType output image is referred to as the
    "labeled image" in this documentation. Each pixel in the image is
    assigned an IdentifierType integer label that groups it within a
    connected region. Some notes on filter parameters Two parameters
    control the output of this filter, Threshold and Level. The units of
    both parameters are percentage points of the maximum height value in
    the input.

    Threshold is used to set the absolute minimum height value used during
    processing. Raising this threshold percentage effectively decreases
    the number of local minima in the input, resulting in an initial
    segmentation with fewer regions. The assumption is that the shallow
    regions that thresholding removes are of of less interest.

    The Level parameter controls the depth of metaphorical flooding of the
    image. That is, it sets the maximum saliency value of interest in the
    result. Raising and lowering the Level influences the number of
    segments in the basic segmentation that are merged to produce the
    final output. A level of 1.0 is analogous to flooding the image up to
    a depth that is 100 percent of the maximum value in the image. A level
    of 0.0 produces the basic segmentation, which will typically be very
    oversegmented. Level values of interest are typically low (i.e. less
    than about 0.40 or 40% ), since higher values quickly start to
    undersegment the image.

    The Level parameter can be used to create a hierarchy of output images
    in constant time once an initial segmentation is done. A typical
    scenario might go like this: For the initial execution of the filter,
    set the Level to the maximum saliency value that you anticipate might
    be of interest. Once the initial Update() of this process object has
    finished, the Level can be manipulated anywhere below the initial
    setting without triggering a full update of the segmentation mini-
    pipeline. All that is now be required to produce the new output is a
    simple relabeling of the output image.

    Threshold and Level parameters are controlled through the class'
    Get/SetThreshold() and Get/SetLevel() methods.
    example{Segmentation/Watersheds/SegmentWithWatershedImageFilter,Wa
    tershed Image Filter} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC3___New_orig__)
    Clone = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC3_Clone)
    GenerateData = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC3_GenerateData)
    SetInput = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC3_SetInput)
    SetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC3_SetThreshold)
    GetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC3_GetThreshold)
    SetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC3_SetLevel)
    GetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC3_GetLevel)
    GetBasicSegmentation = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC3_GetBasicSegmentation)
    GetSegmentTree = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC3_GetSegmentTree)
    InputEqualityComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIUC3_InputEqualityComparableCheck
    
    InputAdditiveOperatorsCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIUC3_InputAdditiveOperatorsCheck
    
    DoubleInputMultiplyOperatorCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIUC3_DoubleInputMultiplyOperatorCheck
    
    InputLessThanComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIUC3_InputLessThanComparableCheck
    
    __swig_destroy__ = _itkWatershedImageFilterPython.delete_itkWatershedImageFilterIUC3
    cast = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC3_cast)

    def New(*args, **kargs):
        """New() -> itkWatershedImageFilterIUC3

        Create a new object of the class itkWatershedImageFilterIUC3 and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkWatershedImageFilterIUC3.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkWatershedImageFilterIUC3.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkWatershedImageFilterIUC3.__New_orig__()
        from itk.support import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkWatershedImageFilterIUC3 in _itkWatershedImageFilterPython:
_itkWatershedImageFilterPython.itkWatershedImageFilterIUC3_swigregister(itkWatershedImageFilterIUC3)
itkWatershedImageFilterIUC3___New_orig__ = _itkWatershedImageFilterPython.itkWatershedImageFilterIUC3___New_orig__
itkWatershedImageFilterIUC3_cast = _itkWatershedImageFilterPython.itkWatershedImageFilterIUC3_cast


def itkWatershedImageFilterIUC4_New():
    return itkWatershedImageFilterIUC4.New()

class itkWatershedImageFilterIUC4(itk.itkImageToImageFilterAPython.itkImageToImageFilterIUC4IUL4):
    r"""


    A low-level image analysis algorithm that automatically produces a
    hierarchy of segmented, labeled images from a scalar-valued image
    input.

    Overview and terminology

    This filter implements a non-streaming version of an image
    segmentation algorithm commonly known as "watershed segmentation".
    Watershed segmentation gets its name from the manner in which the
    algorithm segments regions into catchment basins. If a function $ f $
    is a continuous height function defined over an image domain, then a
    catchment basin is defined as the set of points whose paths of
    steepest descent terminate at the same local minimum of $ f $.

    The choice of height function (input) depends on the application, and
    the basic watershed algorithm operates independently of that choice.
    For intensity-based image data, you might typically use some sort of
    gradient magnitude calculation as input. (see
    itk::GradientMagnitudeImageFilter)

    The watershed algorithm proceeds in several steps. First, an initial
    classification of all points into catchment basin regions is done by
    tracing each point down its path of steepest descent to a local
    minima. Next, neighboring regions and the boundaries between them are
    analyzed according to some saliency measure (such as minimum boundary
    height) to produce a tree of merges among adjacent regions. These
    merges occur at different maximum saliency values. The collective set
    of all possible merges up to a specified saliency "flood level" is
    referred to in this documentation as a "merge tree". Metaphorically,
    the flood level is a value that reflects the amount of precipitation
    that is rained into the catchment basins. As the flood level rises,
    boundaries between adjacent segments erode and those segments merge.
    The minimum value of the flood level is zero and the maximum value is
    the difference between the highest and lowest values in the input
    image.

    Note that once the initial analysis and segmentation is done to
    produce the merge tree, it is trivial to produce a hierarchy of
    labeled images in constant time. The complexity of the algorithm is in
    the computation of the merge tree. Once that tree has been created,
    the initial segmented image can be relabeled to reflect any maximum
    saliency value found in the tree by simply identifying a subset of
    segment merges from the tree. Implementational details This filter is
    a wrapper for several lower level process objects (watershed algorithm
    components in the namespace "watershed"). For a more complete
    picture of the implementation, refer to the documentation of those
    components. The component classes were designed to operate in either a
    data-streaming or a non-data-streaming mode. The pipeline constructed
    in this class' GenerateData() method does not support streaming, but
    is the common use case for the components. Description of the input to
    this filter The input to this filter is a scalar itk::Image of any
    dimensionality. This input image is assumed to represent some sort of
    height function or edge map based on the original image that you want
    to segment (such as would be produced by
    itk::GradientMagnitudeImageFilter). This filter does not do any pre-
    processing on its input other than a thresholding step. The algorithm
    does not explicitly require that the input be of any particular data
    type, but floating point or double precision data is recommended.

    The recommended pre-processing for scalar image input to this
    algorithm is to use one of the itk::AnisotropicDiffusionImageFilter
    subclasses to smooth the original image and then perform some sort of
    edge calculation based on gradients or curvature. Description of the
    output of this filter This filter will produce an itk::Image of
    IdentifierType integer type and of the same dimensionality as the
    input image. The IdentifierType output image is referred to as the
    "labeled image" in this documentation. Each pixel in the image is
    assigned an IdentifierType integer label that groups it within a
    connected region. Some notes on filter parameters Two parameters
    control the output of this filter, Threshold and Level. The units of
    both parameters are percentage points of the maximum height value in
    the input.

    Threshold is used to set the absolute minimum height value used during
    processing. Raising this threshold percentage effectively decreases
    the number of local minima in the input, resulting in an initial
    segmentation with fewer regions. The assumption is that the shallow
    regions that thresholding removes are of of less interest.

    The Level parameter controls the depth of metaphorical flooding of the
    image. That is, it sets the maximum saliency value of interest in the
    result. Raising and lowering the Level influences the number of
    segments in the basic segmentation that are merged to produce the
    final output. A level of 1.0 is analogous to flooding the image up to
    a depth that is 100 percent of the maximum value in the image. A level
    of 0.0 produces the basic segmentation, which will typically be very
    oversegmented. Level values of interest are typically low (i.e. less
    than about 0.40 or 40% ), since higher values quickly start to
    undersegment the image.

    The Level parameter can be used to create a hierarchy of output images
    in constant time once an initial segmentation is done. A typical
    scenario might go like this: For the initial execution of the filter,
    set the Level to the maximum saliency value that you anticipate might
    be of interest. Once the initial Update() of this process object has
    finished, the Level can be manipulated anywhere below the initial
    setting without triggering a full update of the segmentation mini-
    pipeline. All that is now be required to produce the new output is a
    simple relabeling of the output image.

    Threshold and Level parameters are controlled through the class'
    Get/SetThreshold() and Get/SetLevel() methods.
    example{Segmentation/Watersheds/SegmentWithWatershedImageFilter,Wa
    tershed Image Filter} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC4___New_orig__)
    Clone = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC4_Clone)
    GenerateData = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC4_GenerateData)
    SetInput = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC4_SetInput)
    SetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC4_SetThreshold)
    GetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC4_GetThreshold)
    SetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC4_SetLevel)
    GetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC4_GetLevel)
    GetBasicSegmentation = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC4_GetBasicSegmentation)
    GetSegmentTree = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC4_GetSegmentTree)
    InputEqualityComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIUC4_InputEqualityComparableCheck
    
    InputAdditiveOperatorsCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIUC4_InputAdditiveOperatorsCheck
    
    DoubleInputMultiplyOperatorCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIUC4_DoubleInputMultiplyOperatorCheck
    
    InputLessThanComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIUC4_InputLessThanComparableCheck
    
    __swig_destroy__ = _itkWatershedImageFilterPython.delete_itkWatershedImageFilterIUC4
    cast = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUC4_cast)

    def New(*args, **kargs):
        """New() -> itkWatershedImageFilterIUC4

        Create a new object of the class itkWatershedImageFilterIUC4 and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkWatershedImageFilterIUC4.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkWatershedImageFilterIUC4.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkWatershedImageFilterIUC4.__New_orig__()
        from itk.support import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkWatershedImageFilterIUC4 in _itkWatershedImageFilterPython:
_itkWatershedImageFilterPython.itkWatershedImageFilterIUC4_swigregister(itkWatershedImageFilterIUC4)
itkWatershedImageFilterIUC4___New_orig__ = _itkWatershedImageFilterPython.itkWatershedImageFilterIUC4___New_orig__
itkWatershedImageFilterIUC4_cast = _itkWatershedImageFilterPython.itkWatershedImageFilterIUC4_cast


def itkWatershedImageFilterIUS2_New():
    return itkWatershedImageFilterIUS2.New()

class itkWatershedImageFilterIUS2(itk.itkImageToImageFilterAPython.itkImageToImageFilterIUS2IUL2):
    r"""


    A low-level image analysis algorithm that automatically produces a
    hierarchy of segmented, labeled images from a scalar-valued image
    input.

    Overview and terminology

    This filter implements a non-streaming version of an image
    segmentation algorithm commonly known as "watershed segmentation".
    Watershed segmentation gets its name from the manner in which the
    algorithm segments regions into catchment basins. If a function $ f $
    is a continuous height function defined over an image domain, then a
    catchment basin is defined as the set of points whose paths of
    steepest descent terminate at the same local minimum of $ f $.

    The choice of height function (input) depends on the application, and
    the basic watershed algorithm operates independently of that choice.
    For intensity-based image data, you might typically use some sort of
    gradient magnitude calculation as input. (see
    itk::GradientMagnitudeImageFilter)

    The watershed algorithm proceeds in several steps. First, an initial
    classification of all points into catchment basin regions is done by
    tracing each point down its path of steepest descent to a local
    minima. Next, neighboring regions and the boundaries between them are
    analyzed according to some saliency measure (such as minimum boundary
    height) to produce a tree of merges among adjacent regions. These
    merges occur at different maximum saliency values. The collective set
    of all possible merges up to a specified saliency "flood level" is
    referred to in this documentation as a "merge tree". Metaphorically,
    the flood level is a value that reflects the amount of precipitation
    that is rained into the catchment basins. As the flood level rises,
    boundaries between adjacent segments erode and those segments merge.
    The minimum value of the flood level is zero and the maximum value is
    the difference between the highest and lowest values in the input
    image.

    Note that once the initial analysis and segmentation is done to
    produce the merge tree, it is trivial to produce a hierarchy of
    labeled images in constant time. The complexity of the algorithm is in
    the computation of the merge tree. Once that tree has been created,
    the initial segmented image can be relabeled to reflect any maximum
    saliency value found in the tree by simply identifying a subset of
    segment merges from the tree. Implementational details This filter is
    a wrapper for several lower level process objects (watershed algorithm
    components in the namespace "watershed"). For a more complete
    picture of the implementation, refer to the documentation of those
    components. The component classes were designed to operate in either a
    data-streaming or a non-data-streaming mode. The pipeline constructed
    in this class' GenerateData() method does not support streaming, but
    is the common use case for the components. Description of the input to
    this filter The input to this filter is a scalar itk::Image of any
    dimensionality. This input image is assumed to represent some sort of
    height function or edge map based on the original image that you want
    to segment (such as would be produced by
    itk::GradientMagnitudeImageFilter). This filter does not do any pre-
    processing on its input other than a thresholding step. The algorithm
    does not explicitly require that the input be of any particular data
    type, but floating point or double precision data is recommended.

    The recommended pre-processing for scalar image input to this
    algorithm is to use one of the itk::AnisotropicDiffusionImageFilter
    subclasses to smooth the original image and then perform some sort of
    edge calculation based on gradients or curvature. Description of the
    output of this filter This filter will produce an itk::Image of
    IdentifierType integer type and of the same dimensionality as the
    input image. The IdentifierType output image is referred to as the
    "labeled image" in this documentation. Each pixel in the image is
    assigned an IdentifierType integer label that groups it within a
    connected region. Some notes on filter parameters Two parameters
    control the output of this filter, Threshold and Level. The units of
    both parameters are percentage points of the maximum height value in
    the input.

    Threshold is used to set the absolute minimum height value used during
    processing. Raising this threshold percentage effectively decreases
    the number of local minima in the input, resulting in an initial
    segmentation with fewer regions. The assumption is that the shallow
    regions that thresholding removes are of of less interest.

    The Level parameter controls the depth of metaphorical flooding of the
    image. That is, it sets the maximum saliency value of interest in the
    result. Raising and lowering the Level influences the number of
    segments in the basic segmentation that are merged to produce the
    final output. A level of 1.0 is analogous to flooding the image up to
    a depth that is 100 percent of the maximum value in the image. A level
    of 0.0 produces the basic segmentation, which will typically be very
    oversegmented. Level values of interest are typically low (i.e. less
    than about 0.40 or 40% ), since higher values quickly start to
    undersegment the image.

    The Level parameter can be used to create a hierarchy of output images
    in constant time once an initial segmentation is done. A typical
    scenario might go like this: For the initial execution of the filter,
    set the Level to the maximum saliency value that you anticipate might
    be of interest. Once the initial Update() of this process object has
    finished, the Level can be manipulated anywhere below the initial
    setting without triggering a full update of the segmentation mini-
    pipeline. All that is now be required to produce the new output is a
    simple relabeling of the output image.

    Threshold and Level parameters are controlled through the class'
    Get/SetThreshold() and Get/SetLevel() methods.
    example{Segmentation/Watersheds/SegmentWithWatershedImageFilter,Wa
    tershed Image Filter} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS2___New_orig__)
    Clone = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS2_Clone)
    GenerateData = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS2_GenerateData)
    SetInput = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS2_SetInput)
    SetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS2_SetThreshold)
    GetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS2_GetThreshold)
    SetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS2_SetLevel)
    GetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS2_GetLevel)
    GetBasicSegmentation = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS2_GetBasicSegmentation)
    GetSegmentTree = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS2_GetSegmentTree)
    InputEqualityComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIUS2_InputEqualityComparableCheck
    
    InputAdditiveOperatorsCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIUS2_InputAdditiveOperatorsCheck
    
    DoubleInputMultiplyOperatorCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIUS2_DoubleInputMultiplyOperatorCheck
    
    InputLessThanComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIUS2_InputLessThanComparableCheck
    
    __swig_destroy__ = _itkWatershedImageFilterPython.delete_itkWatershedImageFilterIUS2
    cast = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS2_cast)

    def New(*args, **kargs):
        """New() -> itkWatershedImageFilterIUS2

        Create a new object of the class itkWatershedImageFilterIUS2 and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkWatershedImageFilterIUS2.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkWatershedImageFilterIUS2.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkWatershedImageFilterIUS2.__New_orig__()
        from itk.support import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkWatershedImageFilterIUS2 in _itkWatershedImageFilterPython:
_itkWatershedImageFilterPython.itkWatershedImageFilterIUS2_swigregister(itkWatershedImageFilterIUS2)
itkWatershedImageFilterIUS2___New_orig__ = _itkWatershedImageFilterPython.itkWatershedImageFilterIUS2___New_orig__
itkWatershedImageFilterIUS2_cast = _itkWatershedImageFilterPython.itkWatershedImageFilterIUS2_cast


def itkWatershedImageFilterIUS3_New():
    return itkWatershedImageFilterIUS3.New()

class itkWatershedImageFilterIUS3(itk.itkImageToImageFilterAPython.itkImageToImageFilterIUS3IUL3):
    r"""


    A low-level image analysis algorithm that automatically produces a
    hierarchy of segmented, labeled images from a scalar-valued image
    input.

    Overview and terminology

    This filter implements a non-streaming version of an image
    segmentation algorithm commonly known as "watershed segmentation".
    Watershed segmentation gets its name from the manner in which the
    algorithm segments regions into catchment basins. If a function $ f $
    is a continuous height function defined over an image domain, then a
    catchment basin is defined as the set of points whose paths of
    steepest descent terminate at the same local minimum of $ f $.

    The choice of height function (input) depends on the application, and
    the basic watershed algorithm operates independently of that choice.
    For intensity-based image data, you might typically use some sort of
    gradient magnitude calculation as input. (see
    itk::GradientMagnitudeImageFilter)

    The watershed algorithm proceeds in several steps. First, an initial
    classification of all points into catchment basin regions is done by
    tracing each point down its path of steepest descent to a local
    minima. Next, neighboring regions and the boundaries between them are
    analyzed according to some saliency measure (such as minimum boundary
    height) to produce a tree of merges among adjacent regions. These
    merges occur at different maximum saliency values. The collective set
    of all possible merges up to a specified saliency "flood level" is
    referred to in this documentation as a "merge tree". Metaphorically,
    the flood level is a value that reflects the amount of precipitation
    that is rained into the catchment basins. As the flood level rises,
    boundaries between adjacent segments erode and those segments merge.
    The minimum value of the flood level is zero and the maximum value is
    the difference between the highest and lowest values in the input
    image.

    Note that once the initial analysis and segmentation is done to
    produce the merge tree, it is trivial to produce a hierarchy of
    labeled images in constant time. The complexity of the algorithm is in
    the computation of the merge tree. Once that tree has been created,
    the initial segmented image can be relabeled to reflect any maximum
    saliency value found in the tree by simply identifying a subset of
    segment merges from the tree. Implementational details This filter is
    a wrapper for several lower level process objects (watershed algorithm
    components in the namespace "watershed"). For a more complete
    picture of the implementation, refer to the documentation of those
    components. The component classes were designed to operate in either a
    data-streaming or a non-data-streaming mode. The pipeline constructed
    in this class' GenerateData() method does not support streaming, but
    is the common use case for the components. Description of the input to
    this filter The input to this filter is a scalar itk::Image of any
    dimensionality. This input image is assumed to represent some sort of
    height function or edge map based on the original image that you want
    to segment (such as would be produced by
    itk::GradientMagnitudeImageFilter). This filter does not do any pre-
    processing on its input other than a thresholding step. The algorithm
    does not explicitly require that the input be of any particular data
    type, but floating point or double precision data is recommended.

    The recommended pre-processing for scalar image input to this
    algorithm is to use one of the itk::AnisotropicDiffusionImageFilter
    subclasses to smooth the original image and then perform some sort of
    edge calculation based on gradients or curvature. Description of the
    output of this filter This filter will produce an itk::Image of
    IdentifierType integer type and of the same dimensionality as the
    input image. The IdentifierType output image is referred to as the
    "labeled image" in this documentation. Each pixel in the image is
    assigned an IdentifierType integer label that groups it within a
    connected region. Some notes on filter parameters Two parameters
    control the output of this filter, Threshold and Level. The units of
    both parameters are percentage points of the maximum height value in
    the input.

    Threshold is used to set the absolute minimum height value used during
    processing. Raising this threshold percentage effectively decreases
    the number of local minima in the input, resulting in an initial
    segmentation with fewer regions. The assumption is that the shallow
    regions that thresholding removes are of of less interest.

    The Level parameter controls the depth of metaphorical flooding of the
    image. That is, it sets the maximum saliency value of interest in the
    result. Raising and lowering the Level influences the number of
    segments in the basic segmentation that are merged to produce the
    final output. A level of 1.0 is analogous to flooding the image up to
    a depth that is 100 percent of the maximum value in the image. A level
    of 0.0 produces the basic segmentation, which will typically be very
    oversegmented. Level values of interest are typically low (i.e. less
    than about 0.40 or 40% ), since higher values quickly start to
    undersegment the image.

    The Level parameter can be used to create a hierarchy of output images
    in constant time once an initial segmentation is done. A typical
    scenario might go like this: For the initial execution of the filter,
    set the Level to the maximum saliency value that you anticipate might
    be of interest. Once the initial Update() of this process object has
    finished, the Level can be manipulated anywhere below the initial
    setting without triggering a full update of the segmentation mini-
    pipeline. All that is now be required to produce the new output is a
    simple relabeling of the output image.

    Threshold and Level parameters are controlled through the class'
    Get/SetThreshold() and Get/SetLevel() methods.
    example{Segmentation/Watersheds/SegmentWithWatershedImageFilter,Wa
    tershed Image Filter} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS3___New_orig__)
    Clone = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS3_Clone)
    GenerateData = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS3_GenerateData)
    SetInput = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS3_SetInput)
    SetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS3_SetThreshold)
    GetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS3_GetThreshold)
    SetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS3_SetLevel)
    GetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS3_GetLevel)
    GetBasicSegmentation = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS3_GetBasicSegmentation)
    GetSegmentTree = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS3_GetSegmentTree)
    InputEqualityComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIUS3_InputEqualityComparableCheck
    
    InputAdditiveOperatorsCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIUS3_InputAdditiveOperatorsCheck
    
    DoubleInputMultiplyOperatorCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIUS3_DoubleInputMultiplyOperatorCheck
    
    InputLessThanComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIUS3_InputLessThanComparableCheck
    
    __swig_destroy__ = _itkWatershedImageFilterPython.delete_itkWatershedImageFilterIUS3
    cast = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS3_cast)

    def New(*args, **kargs):
        """New() -> itkWatershedImageFilterIUS3

        Create a new object of the class itkWatershedImageFilterIUS3 and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkWatershedImageFilterIUS3.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkWatershedImageFilterIUS3.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkWatershedImageFilterIUS3.__New_orig__()
        from itk.support import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkWatershedImageFilterIUS3 in _itkWatershedImageFilterPython:
_itkWatershedImageFilterPython.itkWatershedImageFilterIUS3_swigregister(itkWatershedImageFilterIUS3)
itkWatershedImageFilterIUS3___New_orig__ = _itkWatershedImageFilterPython.itkWatershedImageFilterIUS3___New_orig__
itkWatershedImageFilterIUS3_cast = _itkWatershedImageFilterPython.itkWatershedImageFilterIUS3_cast


def itkWatershedImageFilterIUS4_New():
    return itkWatershedImageFilterIUS4.New()

class itkWatershedImageFilterIUS4(itk.itkImageToImageFilterAPython.itkImageToImageFilterIUS4IUL4):
    r"""


    A low-level image analysis algorithm that automatically produces a
    hierarchy of segmented, labeled images from a scalar-valued image
    input.

    Overview and terminology

    This filter implements a non-streaming version of an image
    segmentation algorithm commonly known as "watershed segmentation".
    Watershed segmentation gets its name from the manner in which the
    algorithm segments regions into catchment basins. If a function $ f $
    is a continuous height function defined over an image domain, then a
    catchment basin is defined as the set of points whose paths of
    steepest descent terminate at the same local minimum of $ f $.

    The choice of height function (input) depends on the application, and
    the basic watershed algorithm operates independently of that choice.
    For intensity-based image data, you might typically use some sort of
    gradient magnitude calculation as input. (see
    itk::GradientMagnitudeImageFilter)

    The watershed algorithm proceeds in several steps. First, an initial
    classification of all points into catchment basin regions is done by
    tracing each point down its path of steepest descent to a local
    minima. Next, neighboring regions and the boundaries between them are
    analyzed according to some saliency measure (such as minimum boundary
    height) to produce a tree of merges among adjacent regions. These
    merges occur at different maximum saliency values. The collective set
    of all possible merges up to a specified saliency "flood level" is
    referred to in this documentation as a "merge tree". Metaphorically,
    the flood level is a value that reflects the amount of precipitation
    that is rained into the catchment basins. As the flood level rises,
    boundaries between adjacent segments erode and those segments merge.
    The minimum value of the flood level is zero and the maximum value is
    the difference between the highest and lowest values in the input
    image.

    Note that once the initial analysis and segmentation is done to
    produce the merge tree, it is trivial to produce a hierarchy of
    labeled images in constant time. The complexity of the algorithm is in
    the computation of the merge tree. Once that tree has been created,
    the initial segmented image can be relabeled to reflect any maximum
    saliency value found in the tree by simply identifying a subset of
    segment merges from the tree. Implementational details This filter is
    a wrapper for several lower level process objects (watershed algorithm
    components in the namespace "watershed"). For a more complete
    picture of the implementation, refer to the documentation of those
    components. The component classes were designed to operate in either a
    data-streaming or a non-data-streaming mode. The pipeline constructed
    in this class' GenerateData() method does not support streaming, but
    is the common use case for the components. Description of the input to
    this filter The input to this filter is a scalar itk::Image of any
    dimensionality. This input image is assumed to represent some sort of
    height function or edge map based on the original image that you want
    to segment (such as would be produced by
    itk::GradientMagnitudeImageFilter). This filter does not do any pre-
    processing on its input other than a thresholding step. The algorithm
    does not explicitly require that the input be of any particular data
    type, but floating point or double precision data is recommended.

    The recommended pre-processing for scalar image input to this
    algorithm is to use one of the itk::AnisotropicDiffusionImageFilter
    subclasses to smooth the original image and then perform some sort of
    edge calculation based on gradients or curvature. Description of the
    output of this filter This filter will produce an itk::Image of
    IdentifierType integer type and of the same dimensionality as the
    input image. The IdentifierType output image is referred to as the
    "labeled image" in this documentation. Each pixel in the image is
    assigned an IdentifierType integer label that groups it within a
    connected region. Some notes on filter parameters Two parameters
    control the output of this filter, Threshold and Level. The units of
    both parameters are percentage points of the maximum height value in
    the input.

    Threshold is used to set the absolute minimum height value used during
    processing. Raising this threshold percentage effectively decreases
    the number of local minima in the input, resulting in an initial
    segmentation with fewer regions. The assumption is that the shallow
    regions that thresholding removes are of of less interest.

    The Level parameter controls the depth of metaphorical flooding of the
    image. That is, it sets the maximum saliency value of interest in the
    result. Raising and lowering the Level influences the number of
    segments in the basic segmentation that are merged to produce the
    final output. A level of 1.0 is analogous to flooding the image up to
    a depth that is 100 percent of the maximum value in the image. A level
    of 0.0 produces the basic segmentation, which will typically be very
    oversegmented. Level values of interest are typically low (i.e. less
    than about 0.40 or 40% ), since higher values quickly start to
    undersegment the image.

    The Level parameter can be used to create a hierarchy of output images
    in constant time once an initial segmentation is done. A typical
    scenario might go like this: For the initial execution of the filter,
    set the Level to the maximum saliency value that you anticipate might
    be of interest. Once the initial Update() of this process object has
    finished, the Level can be manipulated anywhere below the initial
    setting without triggering a full update of the segmentation mini-
    pipeline. All that is now be required to produce the new output is a
    simple relabeling of the output image.

    Threshold and Level parameters are controlled through the class'
    Get/SetThreshold() and Get/SetLevel() methods.
    example{Segmentation/Watersheds/SegmentWithWatershedImageFilter,Wa
    tershed Image Filter} 
    """

    thisown = property(lambda x: x.this.own(), lambda x, v: x.this.own(v), doc="The membership flag")

    def __init__(self, *args, **kwargs):
        raise AttributeError("No constructor defined")
    __repr__ = _swig_repr
    __New_orig__ = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS4___New_orig__)
    Clone = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS4_Clone)
    GenerateData = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS4_GenerateData)
    SetInput = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS4_SetInput)
    SetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS4_SetThreshold)
    GetThreshold = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS4_GetThreshold)
    SetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS4_SetLevel)
    GetLevel = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS4_GetLevel)
    GetBasicSegmentation = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS4_GetBasicSegmentation)
    GetSegmentTree = _swig_new_instance_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS4_GetSegmentTree)
    InputEqualityComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIUS4_InputEqualityComparableCheck
    
    InputAdditiveOperatorsCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIUS4_InputAdditiveOperatorsCheck
    
    DoubleInputMultiplyOperatorCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIUS4_DoubleInputMultiplyOperatorCheck
    
    InputLessThanComparableCheck = _itkWatershedImageFilterPython.itkWatershedImageFilterIUS4_InputLessThanComparableCheck
    
    __swig_destroy__ = _itkWatershedImageFilterPython.delete_itkWatershedImageFilterIUS4
    cast = _swig_new_static_method(_itkWatershedImageFilterPython.itkWatershedImageFilterIUS4_cast)

    def New(*args, **kargs):
        """New() -> itkWatershedImageFilterIUS4

        Create a new object of the class itkWatershedImageFilterIUS4 and set the input and the parameters if some
        named or non-named arguments are passed to that method.

        New() tries to assign all the non named parameters to the input of the new objects - the
        first non named parameter in the first input, etc.

        The named parameters are used by calling the method with the same name prefixed by 'Set'.

        Ex:

          itkWatershedImageFilterIUS4.New(reader, threshold=10)

        is (most of the time) equivalent to:

          obj = itkWatershedImageFilterIUS4.New()
          obj.SetInput(0, reader.GetOutput())
          obj.SetThreshold(10)
        """
        obj = itkWatershedImageFilterIUS4.__New_orig__()
        from itk.support import itkTemplate
        itkTemplate.New(obj, *args, **kargs)
        return obj
    New = staticmethod(New)


# Register itkWatershedImageFilterIUS4 in _itkWatershedImageFilterPython:
_itkWatershedImageFilterPython.itkWatershedImageFilterIUS4_swigregister(itkWatershedImageFilterIUS4)
itkWatershedImageFilterIUS4___New_orig__ = _itkWatershedImageFilterPython.itkWatershedImageFilterIUS4___New_orig__
itkWatershedImageFilterIUS4_cast = _itkWatershedImageFilterPython.itkWatershedImageFilterIUS4_cast


from itk.support import itkHelpers
@itkHelpers.accept_numpy_array_like_xarray
def watershed_image_filter(*args, **kwargs):
    """Procedural interface for WatershedImageFilter"""
    import itk

    instance = itk.WatershedImageFilter.New(*args, **kwargs)
    return instance.__internal_call__()


def watershed_image_filter_init_docstring():
    import itk
    from itk.support import itkTemplate
    from itk.support import itkHelpers

    filter_class = itk.ITKWatersheds.WatershedImageFilter
    is_template = isinstance(filter_class, itkTemplate.itkTemplate)
    if is_template:
        filter_object = filter_class.values()[0]
    else:
        filter_object = filter_class

    watershed_image_filter.__doc__ = filter_object.__doc__
    watershed_image_filter.__doc__ += "\n args are input(s) to the filter.\n\n"
    watershed_image_filter.__doc__ += "\n Available keyword arguments:\n"
    if is_template:
        watershed_image_filter.__doc__ += itkHelpers.filter_args(filter_object)[0]
        watershed_image_filter.__doc__ += "\n"
        watershed_image_filter.__doc__ += itkHelpers.filter_args(filter_object)[1]
    else:
        watershed_image_filter.__doc__ += "".join(
            [
                "  " + itkHelpers.camel_to_snake_case(item[3:]) + "\n"
                for item in dir(filter_object)
                if item.startswith("Set")
            ]
        )




