"""
    å› ä¸ºkw618çš„initä¸­åªèƒ½å¯¼å…¥å…¨å±€å˜é‡/å‡½æ•°/ç±», è€Œæ— æ³•å¯¼å…¥ç±»ä¸­çš„å‡½æ•°.
    æ‰€ä»¥, å…¶å®æŠŠè¯¥æ¨¡å—ä½œä¸ºä¸€ä¸ª"å¤§çš„ç±»", é‡Œé¢éƒ½æ˜¯ç±»ä¸­å®ç°æŸäº›åŠŸèƒ½çš„å‡½æ•°
    æ‰€ä»¥, docs_2_df å‡½æ•°, å…¶å®æ²¡å¿…è¦å½’çº³åˆ°ç±»ä¸­. è¿™æ ·æ˜¾å¾—å±‚çº§å¾ˆå¤æ‚, è€Œä¸”ä¹Ÿä¸æ–¹ä¾¿å¤–éƒ¨è„šæœ¬è°ƒç”¨è¯¥å‡½æ•°.
"""
import pandas as pd
import numpy as np
import math
import collections
import pymongo
import json
import copy
import hashlib
from io import StringIO

import warnings
warnings.filterwarnings("ignore")

# å¯¼å…¥å¸¸ç”¨çš„å›ºå®šè·¯å¾„(å¤šå¹³å°é€šç”¨)
from kw618._file_path import *

def import_data(
    in_file_name="in", end_index=None, field=None, is_df=True,
    in_file_path=None, encoding="gb18030", index_col=None,
    ):
    """
    in:csvæ–‡ä»¶
    out:dfç±»å‹/ç±»mongoç±»å‹
    function:  csv â†’ df/mongo (é»˜è®¤è½¬å‡º:ç±»mongo)

    notes: in_file_path çš„ä¼˜å…ˆçº§æ¯” in_file_name é«˜ã€‚

    ttt:0214
    """
    if in_file_path:
        df = pd.read_csv(in_file_path, encoding=encoding, engine='python', index_col=index_col)
    else:
        df = pd.read_csv(FILE_PATH_FOR_DESKTOP+"/{0}.csv".format(in_file_name), encoding=encoding, engine='python', index_col=index_col)
    if is_df:
        return df
    # 1.éœ€è¦è¿”å›çš„æ˜¯æŸä¸ªå­—æ®µçš„lstæ ¼å¼
    if field:
        field_lst = df[field].values[:end_index] # å¾—åˆ°çš„æ˜¯np.arrayæ ¼å¼
        return list(field_lst) # ç”¨listæ•°æ®æ ¼å¼æ¥è¿”å›
    # 2.è¿”å›çš„æ˜¯mongoæ”¯æŒçš„docs
    df = df[:end_index]
    docs = df.T.to_dict().values()
    return docs



    #  ä¹Ÿå¯ä»¥ç”¨äº "mongo â†’ df"
def output_data(
    in_obj, out_file_name="out", ordered_field_lst=None,
    out_file_path=None, output=True, index=False, encoding="gb18030", export_excel=False,
    ):
    """
    in:ç±»mongo/df
    out:csvæ–‡ä»¶
    function:  1.mongo/df  â†’ csv
               2.mongo â†’ df (è¿™æ ·outputè®¾ä¸ºFalseå³å¯)

    in_obj:    ä¸ç®¡æ˜¯mongoè¿˜æ˜¯df,è‡ªåŠ¨å…ˆè½¬åŒ–æˆdf,å†ç”¨å®ƒæ¥è½¬csv

    tips: å¦‚æœéœ€è¦ "mongo â†’ df": outputè®¾ç½®ä¸ºFalseå³å¯!
    notes: out_file_path çš„ä¼˜å…ˆçº§æ¯” out_file_name é«˜ã€‚

    """

    # 1. å¦‚æœæ˜¯ "ç±»mongo" ç±»å‹, å…ˆè½¬åŒ–æˆdf
    if isinstance(in_obj, pymongo.cursor.Cursor):
        # total_items = []
        # for doc in in_obj:
        #     # items = {i:str(j).strip() for i, j in zip(list(doc.keys()), list(doc.values()))}
        #     # ä»¥ä¸‹ä¼šæŒ‰ç…§mongoä¸­å­˜ç€çš„é¡ºåºè¿›è¡Œè¾“å‡º!
        #     items = collections.OrderedDict({i:str(j).strip() for i, j in zip(list(doc.keys()), list(doc.values()))})
        #     total_items.append(items)
        # df = pd.DataFrame(total_items)
        df = pd.DataFrame(list(in_obj))  # å¦‚æœin_objçš„æ•°æ®é‡æ˜¯ä¸Šç™¾ä¸‡æ¡, å…¶å®è¿™ä¸ªæ“ä½œå¾ˆå±é™©çš„!!
    elif isinstance(in_obj, pd.core.frame.DataFrame):
        df = in_obj

    # 2.ç¡®å®šå­—æ®µçš„å‘ˆç°é¡ºåº
    if ordered_field_lst:
        # å¦‚æœæŒ‡å®šçš„dfå­—æ®µåœ¨dfä¸­å¹¶ä¸å­˜åœ¨,åˆ™æŠŠè¯¥å­—æ®µremoveæ‰.ç¡®ä¿ä¸æŠ¥é”™
        for field in ordered_field_lst.copy():
            if field not in df.columns:
                print("å­—æ®µ {} ä¸åœ¨dfä¸­,å°†å…¶æŠ›å¼ƒ!".format(field))
                ordered_field_lst.remove(field)
        df = df[ordered_field_lst]  # æŒ‡å®šé¡ºåº

    # 3.çœ‹æ˜¯å¦éœ€è¦å¯¼å‡ºcsvæ–‡ä»¶,å¦‚æœä¸éœ€è¦,ç›´æ¥è¿”å›df
    if not output:
        return df

    # 4. æœ€å,å°†dfæ•°æ®è½¬æˆcsvæ–‡ä»¶è¾“å‡º
    try:
        if out_file_path:
            if not export_excel:
                df.to_csv(out_file_path, index=index, encoding=encoding)
            else:
                df.to_excel(out_file_path, index=index, encoding=encoding)
        else:
            if not export_excel:
                df.to_csv(FILE_PATH_FOR_DESKTOP+"/{0}.csv".format(out_file_name), index=index, encoding=encoding)
            else:
                df.to_excel(FILE_PATH_FOR_DESKTOP+"/{0}.xlsx".format(out_file_name), index=index, encoding=encoding)
    except Exception as e:
        print(e)
        out_file_name = input("è¾“å‡ºæ–‡ä»¶åå‡ºé”™,è¯·é‡æ–°é”®å…¥æ–‡ä»¶å: ")
        df.to_csv(FILE_PATH_FOR_DESKTOP+"/{0}.csv".format(out_file_name), index=index, encoding=encoding)

    return df


# class KwPd():
#     def __init__(self):
#         pass
#
#     def docs_2_df(self, docs, ordered_field_lst=None):
#         """
#         æŠŠmongoçš„æ•°æ®è½¬åŒ–æˆdf
#         """
#         df = output_data(docs, output=False, ordered_field_lst=ordered_field_lst)
#         return df



def docs_to_df(docs, ordered_field_lst=None):
    """
    æŠŠmongoçš„æ•°æ®è½¬åŒ–æˆdf
    """
    df = output_data(docs, output=False, ordered_field_lst=ordered_field_lst)
    return df


def df_2_mongo(df):
    return df.T.to_dict().values() # å³ï¼šdocs
def df_to_docs(df, is_lst=False):
    """
        notices:
            1. è¿™é‡Œä¼ å…¥çš„dfçš„index, åº”è¯¥åªå…è®¸ 0/1/2...999 çš„è‡ªç„¶æ•°.
                (ä¸ç¡®å®š. æˆ‘æŠŠdatetimeå¯¹è±¡ä½œä¸ºindexæ˜¯ä¼šæŠ¥é”™çš„)
            [å·¨å‘]: ä¸€å®šè¦æ³¨æ„ pd.concat([df1, df2], axis=0)çš„æƒ…å†µ, ä¸€å®šè¦åŠ ä¸Š ignore_index=True !!!

            2. //20200812æ›´æ–°: å¯ä»¥ä½¿ç”¨pandasè‡ªå¸¦çš„æ–¹æ³•å®ç°, æ–¹ä¾¿é«˜æ•ˆ!!!
                (è€Œä¸”è¿™ç§æ–¹å¼éƒ½ä¸ç”¨æ‹…å¿ƒå‡ºç°ä¸Šé¢çš„ åˆ¤æ–­pd.concat()ä¸­çš„ç´¢å¼•é‡å¤å¯¼è‡´è½¬åŒ–ç¼ºå¤±çš„é—®é¢˜)
    """
    # //20200812æ›´æ–°: å¯ä»¥ä½¿ç”¨pandasè‡ªå¸¦çš„æ–¹æ³•å®ç°, æ–¹ä¾¿é«˜æ•ˆ!!!
    # if is_lst:
    #     return list(df.T.to_dict().values())
    # else:
    #     return df.T.to_dict().values() # å³ï¼šdocs

    docs = df.to_dict("records") # é«˜æ•ˆ!!
    return docs


def read_excel(in_file_name="in", in_file_path=None, sheet_name=None, need_to_concat=True):
    """
        params:
            sheet_name:
                ä¼ å…¥None: è¿”å›ä¸€ä¸ªæœ‰åºå­—å…¸ OrderedDict([("<sheetåå­—>", <dfå¯¹è±¡>)])
                        ( éœ€è¦ç”¨sheetåæ¥æŒ‰é”®å–å€¼)
            need_to_concat:
                å½“æ²¡æœ‰æŒ‡å®š"sheet_name"æ—¶, é»˜è®¤æŠŠæ‰€æœ‰sheetåˆå¹¶, è¿”å›åˆå¹¶åçš„df
                    (å½“need_to_concatä¸ºFalseæ—¶, ä¸è‡ªåŠ¨åˆå¹¶sheet, è€Œæ˜¯è¿”å›ä¸€ä¸ª 'excelå­—å…¸å¯¹è±¡')
    """
    # 1. å…ˆè¯»å–æ•´ä¸ªexcelæ–‡ä»¶
    if in_file_path is not None:
        ordered_d = pd.read_excel(in_file_path, sheet_name=None)
    elif in_file_path is None:
        ordered_d = pd.read_excel(f"{FILE_PATH_FOR_DESKTOP}/{in_file_name}.xlsx", sheet_name=None)

    # 2. è¯»å–å¯¹åº”sheet_name (è¿”å›df)
    if sheet_name != None:
        df = ordered_d.get(sheet_name)
        del ordered_d # é‡Šæ”¾ä¸­é—´è¿‡ç¨‹å¯¹è±¡çš„å†…å­˜
        return df
    # 3. åˆå¹¶å¤šä¸ªsheet, è¿”å›åˆå¹¶åçš„df
    elif need_to_concat == True:
        concat_df = pd.concat([sheet for sheet in ordered_d.values()], axis=0, ignore_index=True)
        del ordered_d # é‡Šæ”¾ä¸­é—´è¿‡ç¨‹å¯¹è±¡çš„å†…å­˜
        return concat_df

    # 4. è¿”å›è¿™ä¸ªexcelå­—å…¸å¯¹è±¡ (æ¯ä¸ªé”®å€¼å¯¹ä¸­, ä»¥sheetçš„åå­—ä½œä¸º"é”®", å¯¹åº”çš„dfå¯¹è±¡ä½œä¸º"å€¼")
    return ordered_d


def sort_df(df, ordered_field_lst):
    # 1. å¦‚æœæŒ‡å®šçš„å­—æ®µåœ¨dfä¸­å¹¶ä¸å­˜åœ¨,åˆ™æŠŠè¯¥å­—æ®µremoveæ‰.ç¡®ä¿ä¸æŠ¥é”™
    ordered_field_lst_copy = ordered_field_lst.copy()
    for field in ordered_field_lst_copy:
        if field not in df.columns:
            print("å­—æ®µ {} ä¸åœ¨dfä¸­, å°†å…¶æŠ›å¼ƒ!".format(field))
            ordered_field_lst.remove(field)

    # 2. æŠŠæ‰€éœ€è¦ä¿ç•™çš„ "æœ‰åºå­—æ®µlist" ä½œç”¨åœ¨dfä¸Š
    return df[ordered_field_lst]  # æŒ‡å®šé¡ºåº




# stackoverflow ç™½å«–æ¥çš„å‡½æ•°ï¼Œhhh
def read_mongo(collection_obj, query={}, need_to_show_dict={}, df_name="foo", need_to_convert_date=True):
    """
        params:
            need_to_convert_date: æ˜¯å¦éœ€è¦åœ¨è¯»å–mongoæ•°æ®çš„æ—¶å€™, è½¬åŒ–æ—¥æœŸæ ¼å¼
        note: ç™½å«–æ¥çš„å‡½æ•°, hhh

    """

    # ä¸éœ€è¦è·å–"_id"å­—æ®µ
    need_to_show_dict.update({"_id":0})

    # Make a query to the specific DB and Collection
    # print(query, need_to_show_dict)
    cursor = collection_obj.find(query, need_to_show_dict)

    # Expand the cursor and construct the DataFrame
    df =  pd.DataFrame(list(cursor))

    df.df_name = df_name


    if ("crawl_date" in df.columns) and (need_to_convert_date==True):
        df["crawl_date"] = pd.to_datetime(df["crawl_date"])
    if ("date" in df.columns) and (need_to_convert_date==True):
        df["date"] = pd.to_datetime(df["date"])

    return df





def date_to_obj(date_str="today"):
    return pd.to_datetime(date_str)

def obj_to_date(date_obj, format_="%Y-%m-%d"):
    return date_obj.strftime(format_)

def get_today_obj(date_str="today"):
    return pd.to_datetime(date_str)

def get_days(days_str="1 d"):
    "1å¤©çš„æ—¶é—´æ®µ"
    return pd.to_timedelta(days_str)

def get_this_time():
    "æ­¤åˆ»çš„æ—¶é—´"
    today_obj = pd.to_datetime("today")
    return today_obj.strftime("%X") # è½¬æˆâ€œ15:43:36â€è¿™æ ·çš„strå½¢å¼

def get_this_date_time():
    "æ­¤åˆ»çš„æ—¶é—´"
    today_obj = pd.to_datetime("today")
    return today_obj.strftime("%Y-%m-%d %X") # è½¬æˆ '2020-07-29 14:13:30' è¿™æ ·çš„strå½¢å¼


def get_today_date(date_str="today", format_="%Y-%m-%d"):
    "ä»Šå¤©çš„æ—¥æœŸ"
    today_obj = pd.to_datetime(date_str)
    return today_obj.strftime(format_) # è½¬æˆâ€œ2019-02-28â€è¿™æ ·çš„strå½¢å¼
# ç®€åŒ–ç‰ˆçš„å½“å‰æ—¥æœŸ
def get_sim_today_date(date_str="today"):
    return get_today_date(date_str=date_str ,format_="%m%d") # è½¬æˆâ€œ0228â€è¿™æ ·çš„strå½¢å¼
# ç®€åŒ–ç‰ˆçš„æ˜¨å¤©æ—¥æœŸ
def get_sim_yesterday_date(date_str="today"):
    return get_yesterday_date(date_str=date_str, format_="%m%d") # è½¬æˆâ€œ0228â€è¿™æ ·çš„strå½¢å¼

def get_sim_this_time():
    this_time_str = get_this_time() # '03:05:49'
    return this_time_str.replace(":", "") # '030549'

def get_yesterday_obj(date_str="today"):
    today_obj = pd.to_datetime(date_str)
    yesterday_obj = today_obj - pd.to_timedelta("1 d")
    return yesterday_obj

def get_yesterday_date(date_str="today", format_="%Y-%m-%d"):
    " æ˜¨å¤©çš„æ—¥æœŸ"
    today_obj = pd.to_datetime(date_str)
    yesterday_obj = today_obj - pd.to_timedelta("1 d")
    yesterday_date = yesterday_obj.strftime(format_) # è½¬æˆâ€œ20190228â€è¿™æ ·çš„strå½¢å¼
    return yesterday_date

def get_previous_date(date_str="today", days_str="10 d", format_="%Y-%m-%d"):
    today_obj = pd.to_datetime(date_str)
    days_obj = get_days(days_str)
    previous_date_obj = today_obj - days_obj
    previous_date = previous_date_obj.strftime(format_)
    return previous_date

def get_later_date(date_str="today", days_str="10 d", format_="%Y-%m-%d"):
    today_obj = pd.to_datetime(date_str)
    days_obj = get_days(days_str)
    previous_date_obj = today_obj + days_obj
    previous_date = previous_date_obj.strftime(format_)
    return previous_date



def get_this_month_first_date(date_str="today"):
    " æœ¬æœˆç¬¬ä¸€å¤©çš„æ—¥æœŸ"
    today_obj = get_today_obj(date_str)
    this_month_first_obj = get_today_obj(today_obj.strftime("%Y-%m"))
    this_month_first_date = obj_to_date(this_month_first_obj)
    return this_month_first_date


def get_delta_days(start_date=get_yesterday_date(), end_date=get_today_date()):
    start_date_obj = get_today_obj(date_str=start_date)
    end_date_obj = get_today_obj(date_str=end_date)
    delta_days = (end_date_obj - start_date_obj).days
    return delta_days


def get_period_df(start_date=None, end_date=None, is_crawl_date=False):
    " è·å–ä¸€æ®µæ—¶é—´å†…çš„ <æ—¥æœŸæ‰©å……è¡¨> "
    if start_date is None:
        this_month_first_date = get_this_month_first_date()
        start_date = this_month_first_date
    if end_date is None:
        end_date = get_today_date()

    # ä¸¤ç§æ–¹å¼æˆªå– "æ—¥æœŸèŒƒå›´"
    datetime_index = pd.date_range(start_date, end_date, freq="1d")
    if is_crawl_date: # ç”¨"crawl_date"æ¥é€‰æ‹© "æ—¥æœŸèŒƒå›´"
        df = pd.DataFrame({"crawl_date":datetime_index})
        df["true_date"] = df.crawl_date - get_days("1 d")
    else: # ç”¨"true_date"æ¥é€‰æ‹© "æ—¥æœŸèŒƒå›´"
        df = pd.DataFrame({"true_date":datetime_index})
        df["crawl_date"] = df.true_date + get_days("1 d")

    # ç”Ÿæˆ4ä¸­ stræ ¼å¼çš„æ—¥æœŸ  (ç”¨äºåæœŸé€è§†)
    df["æ—¥æœŸ"] = df.true_date.dt.strftime("%Y-%m-%d")
    df["æ—¥æœŸ-å¹´"] = df.true_date.dt.strftime("%Y") # seriesç±»å‹æ­£å¸¸æ¥è¯´æ˜¯ä¸èƒ½ç›´æ¥strftimeæˆstrç±»å‹çš„, å¿…é¡»è¦ç”¨.dt æ–¹æ³•æ‰è¡Œ
    df["æ—¥æœŸ-æœˆ"] = df.true_date.dt.strftime("%Y-%m")
    # è®¡ç®—"æ—¥æœŸ-å‘¨"è¿™ä¸ª 'å‘¨åº¦æ—¥æœŸ '
    weekly_date_lst = []
    for count, date_str in enumerate(df["æ—¥æœŸ"][-1::-1]): # å¯¹'æ—¥æœŸ'çš„seriesé€†åº
        if count % 7 == 0:
            tmp = date_str
        weekly_date_lst.append(tmp)
    df["æ—¥æœŸ-å‘¨"] = weekly_date_lst[-1::-1] # ä¸Šé¢é€†åºäº†, ç°åœ¨é€†åºå›æ¥
    df["sim_true_date"] = df.true_date.dt.strftime("%m%d")
    df["sim_crawl_date"] = df.crawl_date.dt.strftime("%m%d")

    return df





def output_excel(df_lst, out_file_name="out", out_file_path=None, sheet_name_lst=None):
    from pandas import ExcelWriter
    if out_file_path is None:
        # å¦‚æœæ²¡æœ‰out_file_path: é»˜è®¤æ”¾åœ¨æ¡Œé¢
        out_file_path = f"{FILE_PATH_FOR_DESKTOP}/{out_file_name}.xlsx"
    with ExcelWriter(out_file_path) as writer:
        for i, df in enumerate(df_lst):
            if sheet_name_lst:
                sheet_name = sheet_name_lst[i]
            else:
                sheet_name = f"sheet_{i}"
            df.to_excel(writer, sheet_name, index=False)
        writer.save()















def avg(lst):
    if isinstance(lst, list):
        if len(lst) <1:
            # raise myError("å…ƒç´ å°äº1!")
            return 0
    elif isinstance(lst, type(pd.Series())):
        if lst.size <1:
            # raise myError("å…ƒç´ å°äº1!")
            return 0
    sum = 0
    for count, e in enumerate(lst):
        # print(count, e)
        sum += int(float(e))
    lst_avg = sum/(count+1)
    # print(lst_avg)
    return int(lst_avg)


def merge_df(
    x_name, y_name, out_file_name="out",
    is_df=None, join_field="house_id", output=True):
    """
    function: ä¸ä»…å¯ä»¥åˆå¹¶df/csv, è¿˜é™„å¸¦è¾“å‡ºcsvçš„åŠŸèƒ½
    """
    print(">>>1")
    if not is_df:
        # å¦‚æœ ä¸æ˜¯dfï¼Œ å°±æŠŠè¿™ä¸ªå½“åšæ–‡ä»¶åï¼Œå¯¼å…¥
        x_df = import_data(x_name, is_df=True)
        y_df = import_data(y_name, is_df=True)
    else:
        # å¦‚æœ æ˜¯dfï¼Œ å°±ç›´æ¥æŠŠä¼ å…¥çš„xã€yå½“åš dfå¯¹è±¡æ¥ä½¿ç”¨
        x_df = x_name
        y_df = y_name
    print(">>>2")
    # pd.merge() è¿”å›çš„ä¸æ˜¯dfç±»å‹ï¼Œè€Œæ˜¯functionç±»å‹ã€‚ ä½†è¿™ä¸ªfunctionå¯ä»¥ä½¿ç”¨to_csvå¯¼å‡ºæ–‡ä»¶
    #  ??????   ä»€ä¹ˆæƒ…å†µï¼Ÿ ä¹‹å‰æµ‹è¯•çš„æ—¶å€™è¿”å›çš„ä¸æ˜¯dfå¯¹è±¡ï¼Œç°åœ¨æµ‹è¯•å‘ç°åˆç¡®å®æ˜¯dfå¯¹è±¡äº†ã€‚ã€‚ã€‚è§é¬¼ï¼
    merged_df = pd.merge(x_df, y_df, how="left", on=join_field)
    if not output:
        return merged_df
    print(">>>3")
    merged_df.to_csv(FILE_PATH_FOR_DESKTOP+"/{0}.csv".format(out_file_name), index=False, encoding="gb18030")
    print("åˆå¹¶æˆåŠŸ!")

# merge_df("aaa", "bbb", out_file_name="zzzz")
# exit()


# def k_top(lst, top=1):
#     if isinstance(lst, list):
#         if len(lst) <1:
#             # raise myError("å…ƒç´ å°äº1!")
#             return 0
#     elif isinstance(lst, type(pd.Series())):
#         if lst.size <1:
#             # raise myError("å…ƒç´ å°äº1!")
#             return 0
#
#     lst = sorted(lst)
#     return lst[top-1]


class NumpyEncoder(json.JSONEncoder):
    """ Special json encoder for np types """
    def default(self, obj):
        if isinstance(obj, (np.int_, np.intc, np.intp, np.int8,
                            np.int16, np.int32, np.int64, np.uint8,
                            np.uint16, np.uint32, np.uint64)):
            return int(obj)
        elif isinstance(obj, (np.float_, np.float16, np.float32,
                              np.float64)):
            return float(obj)
        elif isinstance(obj, (np.ndarray,)):
            return obj.tolist()
        return json.JSONEncoder.default(self, obj)










def k_divide(lst, piece=5):
    """
    function: æŒ‰lstä»å°åˆ°å¤§çš„é¡ºåº, ç­‰åˆ†æˆpieceä»½ å°lst è¿”å›
    return: è¿”å›ç­‰åˆ†èŠ‚ç‚¹çš„lst (å³:æŒ‰ç…§è¿™å‡ ä¸ªå€¼å»æˆªå–, å°±æ˜¯5ç­‰åˆ†äº†)
    """
    if isinstance(lst, list):
        if len(lst) <1:
            # raise myError("å…ƒç´ å°äº1!")
            return 0
    elif isinstance(lst, type(pd.Series())):
        if lst.size <1:
            # raise myError("å…ƒç´ å°äº1!")
            return 0

    lst = sorted(lst)
    # 1. æ‰“å°åŸlst
    print(lst)
    node_order_lst = []
    node_lst = []
    for count in range(1, piece):
        node_order_value = round(len(lst) * (1/piece) * count) - 1 # å‡ä¸€åˆ«å¿˜äº† (å¦å¤–,è¿™é‡Œè¿”å›çš„æ˜¯é¡ºåºå€¼,ä¸æ˜¯çœŸå®å€¼)
        node_order_lst.append(node_order_value)
        node_lst.append(lst[node_order_value])
    # 2. æ‰“å°åˆ†å¥½pieceåçš„, èŠ‚ç‚¹çš„é¡ºåº
    print(node_order_lst) # æ˜¯é¡ºåº
    print("å€¼çš„lst: {}".format(node_lst)) # æ˜¯å€¼

    piece_dict = {}
    count = 0
    while True:
        if count == piece:
            break
        elif count == 0:
            piece_dict.update({count+1 : lst[ : node_order_lst[count]+1]})
        elif count == piece-1:
            piece_dict.update({count+1 : lst[node_order_lst[count-1]+1 : ]})
        else:
            piece_dict.update({count+1 : lst[node_order_lst[count-1]+1 : node_order_lst[count]+1]})
        count += 1
    # 3. æ‰“å°æ ¹æ®ä¸Šé¢çš„é¡ºåº, pieceç­‰æ‹†åˆ†äº†lståçš„dict
    print(piece_dict)
    return node_lst
    # return piece_dict


    # piece_lst = [] count = 0
    # while True:
    #     if count == piece:
    #         break
    #     elif count == 0:
    #         piece_lst.append(lst[ : node_order_lst[count]+1])
    #     elif count == piece-1:
    #         piece_lst.append(lst[node_order_lst[count-1]+1 : ])
    #     else:
    #         piece_lst.append(lst[node_order_lst[count-1]+1 : node_order_lst[count]+1])
    #     count += 1
    # # 3. æ‰“å°æ ¹æ®ä¸Šé¢çš„é¡ºåº, pieceç­‰æ‹†åˆ†äº†lståçš„lst
    # print(piece_lst)
    # return piece_lst

# k_divide([3, 4, 5, 7, 2, 4, 46, 6, 7, 84, 4,5], 5)




def is_notnan_numeric(x):
    """
        numeric: æŒ‡æ‰€æœ‰æ•°å€¼: int/float (åŒ…æ‹¬np.nan) (ä¸åŒ…æ‹¬None) (ä¸åŒ…æ‹¬'å¯ä»¥è½¬æˆfloatçš„str')
        notnan_numeric: æŒ‡æ‰€æœ‰'énan'çš„æ•°å€¼: int/float (ä¸åŒ…æ‹¬np.nan, ä¸åŒ…æ‹¬None)
    """
    # 1. è‹¥æ˜¯æ•°æ®é›†, åˆ™ç›´æ¥è¿”å›False
    if isinstance(x, list) or isinstance(x, dict) or isinstance(x, set) or isinstance(x, tuple) or isinstance(x, np.ndarray):
        return False
    # 2. æ˜¯å¦ä¸º None
    if x is None:
        return False
    # 3. æ˜¯å¦ä¸º np.nan
    elif pd.isnull(x):
        return False
    # 4. æ˜¯å¦ä¸º str
    elif isinstance(x, str):
        ### æ³¨æ„: è¿™é‡Œé˜²æ­¢xä¸ºå¯ä»¥è¢«è½¬æˆfloatçš„str, å…ˆå¯¹strç±»å‹å•ç‹¬å¤„ç† (é¿å…ä¸‹ä¸€æ­¥é€ æˆé”™è¯¯åˆ¤æ–­)
        return False
    else:
        try:
            # 4. å¦‚æœå¯ä»¥è¢«float()è½¬åŒ–æˆfloat, åˆ™xæ˜¯ä¸ºæ•°å€¼å‹, è¿”å›True
            return isinstance(float(x), float)
        except:
            # 5. ä¸èƒ½è½¬åŒ–, åˆ™è¯´æ˜ä¸æ˜¯æ•°å€¼å‹
            return False


def safely_to_int(x, need_to_print=False):
    """
        save: è¡¨ç¤ºå¯ä»¥'å®‰å…¨'è½¬åŒ–æˆ'int'. å¦‚æœxä¸ºä¸èƒ½è½¬åŒ–æˆintçš„æ•°æ®, åˆ™ä¿ç•™åŸæ ·
        notice: è¯¥å‡½æ•°æ˜¯ä»¥'å››èˆäº”å…¥'çš„æ–¹å¼è½¬æˆint
    """
    # å¦‚æœæ˜¯'énanæ•°å€¼å‹', åˆ™ç›´æ¥round()
    if is_notnan_numeric(x):
        ### ä¸ºäº†ä¿è¯è½¬æˆint, éœ€è¦å…ˆå››èˆäº”å…¥, å†è½¬æˆint
        ### æ³¨æ„: å¦‚æœx=np.float(3.5000) , round(x, 0)  >>> 4.0 (è¿˜æ˜¯ä¼šå¸¦ä¸ªå°æ•°ç‚¹,å¾ˆçƒ¦,æ‰€ä»¥å¹²è„†è½¬æˆintæ˜¯æœ€çœå¿ƒ/æœ€å¹²å‡€çš„)
        return int(round(x, 0))
    # å¦åˆ™: åŸæ ·returnå›å»
    else:
        if need_to_print:
            print(f"x: {x}, ç±»å‹ä¸º: {type(x)}, ä¸èƒ½ä¿ç•™æ•´æ•°!\n")
        return x







def round_df(df, round_digit=0, inplace=False, included_columns=[], excluded_columns=[]):
    """
        params:
            round_digit: ä¿ç•™çš„å°æ•°ä½æ•°
            inplace: æ˜¯å¦åœ¨åŸdfä¸Šæ“ä½œ?
            excluded_columns: æ’é™¤æŸäº›ä¸éœ€è¦è½¬åŒ–çš„åˆ—
            included_columns: åªæœ‰è¿™äº›åˆ— éœ€è¦è¢«è½¬åŒ–


        é»˜è®¤:
            1. å››èˆäº”å…¥åˆ°æ•´æ•°
            2. åˆ—åä¸º"xxç‡"çš„, ä¸€å¾‹ä»¥é™„å¸¦"ç™¾åˆ†å·", ä»¥strçš„å½¢å¼å‘ˆç°
    """
    if inplace is False:
        df = copy.deepcopy(df)

    for column, dtype in df.dtypes.items():
        # 1. æœ‰äº›'ç‡'æ˜¯éœ€è¦è½¬åŒ–æˆ'ç™¾åˆ†æ•°'çš„
        if "ç‡" in column:
            df[column] = df[column].apply(lambda x: format(x, ".2%"))
        # 2. è‹¥å‘ç°dfä¸­çš„æŸåˆ—æ˜¯ intå‹æˆ–è€…floatå‹, åˆ™æŒ‰ç…§round_digitå››èˆäº”å…¥
        else:
            # 1. å½“ä»…ä»…éœ€è¦æŸå‡ ä¸ªåˆ—éœ€è¦è½¬åŒ–æ—¶:
            if included_columns:
                if column in included_columns:
                    if dtype == np.dtype(np.float64) or dtype == np.dtype(np.int64):
                        df[column] = df[column].round(round_digit)
            # 2. å½“æŸå‡ ä¸ªåˆ— ä¸€å®šä¸èƒ½è½¬åŒ–æ—¶:
            elif excluded_columns:
                if column not in excluded_columns: # åªæœ‰'ä¸è¢«æ’é™¤åˆ—'æ‰éœ€è¦ä¿ç•™ä¸¤ä½å°æ•°
                    if dtype == np.dtype(np.float64) or dtype == np.dtype(np.int64):
                        df[column] = df[column].round(round_digit)
            # 3. å½“éƒ½æ²¡æœ‰é™åˆ¶æ¡ä»¶æ—¶:
            else:
                if dtype == np.dtype(np.float64) or dtype == np.dtype(np.int64):
                    df[column] = df[column].round(round_digit)
    return df



def get_random_num():
    "è·å–ä¸€ä¸ª [0.0, 1.0) çš„éšæœºæ•°"
    return np.random.rand(1)[0]


def get_random_df(df):
    "å¯¹dfçš„æ¯ä¸€è¡Œæ‰“ä¹±é¡ºåº"
    random_df = pd.DataFrame(np.random.permutation(df), columns=df.columns)
    return random_df



def k_md5(s: str):
    """
        function: è·å–md5å“ˆå¸Œç¼–ç åçš„å€¼;
        è¾“å…¥ç±»å‹: å¿…é¡»ä¸ºstr (å› ä¸ºéœ€è¦encode, å…¶ä»–ç±»å‹éƒ½ä¸èƒ½encode)
        è¿”å›ç±»å‹: ä¸ºstr
        notes: md5æ˜¯ä¸å¯é€†çš„åŠ å¯† (ä¸å±äºå¯¹ç§°åŠ å¯†å’Œéå¯¹ç§°åŠ å¯†)
    """
    if isinstance(s, str) is False:
        raise Exception("[error]: è¾“å…¥ç±»å‹ä¸æ˜¯str\n")
    MD5 = hashlib.md5()
    MD5.update(s.encode("utf-8"))
    encrypted_s = MD5.hexdigest()
    print(f"åŠ å¯†åçš„å€¼ä¸º: {encrypted_s}\n")
    return encrypted_s

def k_sha256(s: str):
    """
        function: è·å–sha256å“ˆå¸Œç¼–ç åçš„å€¼;
        è¾“å…¥ç±»å‹: å¿…é¡»ä¸ºstr (å› ä¸ºéœ€è¦encode, å…¶ä»–ç±»å‹éƒ½ä¸èƒ½encode)
        è¿”å›ç±»å‹: ä¸ºstr
        notes: sha256æ˜¯ä¸å¯é€†çš„åŠ å¯† (ä¸å±äºå¯¹ç§°åŠ å¯†å’Œéå¯¹ç§°åŠ å¯†)

        (æ–¹æ³•ä¸ä¸Šé¢çš„md5åŸºæœ¬ä¸€æ ·..)
    """
    if isinstance(s, str) is False:
        raise Exception("[error]: è¾“å…¥ç±»å‹ä¸æ˜¯str\n")
    SHA256 = hashlib.sha256()
    SHA256.update(s.encode("utf-8"))
    encrypted_s = SHA256.hexdigest()
    print(f"åŠ å¯†åçš„å€¼ä¸º: {encrypted_s}\n")
    return encrypted_s


def k_hmac_sha256(key, data):
    """
    (ç½‘ä¸Šç™½å«–æ¥çš„æ–¹æ³•)
        function: æ ¹æ® hmac sha256 ç®—æ³•, ä½¿ç”¨ key ä½œä¸ºå¯†é’¥, å¯¹ data è¿›è¡ŒåŠ å¯† (åº”è¯¥æ˜¯åŒ…å«äº†å“ˆå¸ŒåŠ å¯†å’Œå¯¹ç§°åŠ å¯†ä¸¤éƒ¨åˆ†)
                (åº”è¯¥æ˜¯æ¯”å•çº¯çš„sha256æ›´å®‰å…¨?)
        params:
            key: å¯†é’¥
            data: éœ€è¦åŠ å¯†çš„æ•°æ®
        return: åŠ å¯†åçš„æ•°æ®
    """

    import hmac
    data = data.encode('utf-8')
    encrypted_data = hmac.new(key.encode('utf-8'), data, digestmod=hashlib.sha256).hexdigest().upper()
    print(f"\n\nåŠ å¯†åçš„æ•°æ®: {encrypted_data}\n\n")
    return encrypted_data


def get_binance_sign(secret_key, ori_params):
    """
        function: ç”Ÿæˆå¸å®‰çš„ç­¾å
        params:
            secret_key: ä½¿ç”¨ SECRETKEY ä½œä¸ºå¯†é’¥
            ori_params: stræ ¼å¼çš„'åŸè¯·æ±‚å‚æ•°'
        return: stræ ¼å¼çš„'ç­¾å'
    """
    signature = k_hmac_sha256(key=secret_key, data=ori_params)
    print(f"\n\nè¯¥è¯·æ±‚çš„å¸å®‰ç­¾åä¸º: {signature}\n\n")
    return signature


def create_encrypted_cookie(key: str, salt="618"):
    "é€šè¿‡åŠ ç›, åŠ æ—¶é—´æ•°, åŠ éšæœºæ•°, è·å¾—ä¸€ä¸ªmd5åŠ å¯†åçš„éšæœºcookies (å…¶å®ä¹Ÿæ²¡å¿…è¦åŠ å¯†,åªæ˜¯ç”¨äºè®°å½•ç™»å½•çŠ¶æ€,å¹¶æ²¡æœ‰å…¶ä»–ä½œç”¨)"
    "åº”ç”¨åœºæ™¯: æœåŠ¡ç«¯è®°å½•è¿™ä¸ªå“ˆå¸Œå€¼, ç”¨äºéªŒè¯æµè§ˆå™¨çš„30åˆ†é’Ÿæœ‰æ•ˆç™»å½•"
    s = key + salt + get_sim_this_time() + str(np.random.randint(10, 1000000))
    encrypted_s = k_md5(s)
    return encrypted_s





def kplot(df, kind="line"):
    """
        params:
            kind:
                line: æŠ˜çº¿å›¾
                bar: æ¡å½¢å›¾ğŸ“Š (ç«–ç›´å‹, å¦‚å·¦å›¾æ ‡) [indexä¸Šçš„ç´¢å¼•, å°±ä»£è¡¨çš„æ˜¯åæ ‡è½´ä¸Šçš„æ ‡ç­¾]
                barh: æ¡å½¢å›¾ (æ°´å¹³å‹)
                hist: ç›´æ–¹å›¾ (æ¯ä¸ªå€¼çš„é¢‘ç‡å›¾) (ç±»ä¼¼äºæ›å…‰ç›´æ–¹å›¾)
                pie: é¥¼çŠ¶å›¾

        todo:
            1. å¦‚ä½•å¯¹dfä¸­çš„æŸä¸€åˆ—, æ ‡æ³¨çº¢è‰², ä¸”åŠ ç²—?? (å…¶ä»–è®¾ç½®æˆç°è‰²/æµ…è‰²è™šçº¿?)

    """
    import matplotlib.pyplot as plt
    plt.figure()
    df.plot()
    plt.show()








if __name__ == '__main__':
    print("start!")
    df = import_data("ä¸šåŠ¡åé¦ˆè°ƒä»·", is_df=True)
    print(df)
    print(df.shape)
    print("end!")
